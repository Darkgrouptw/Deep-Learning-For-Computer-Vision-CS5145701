{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous exercises, you implemented linear models for regression and multi-class classification. In this exercise, you will combine those ideas to create neural networks with arbitrary number of layers to perform multi-class classification, also called multi-layered perceptrons.\n",
    "\n",
    "**You will learn to:**\n",
    "- Compute Numerical Gradients to be used as gradient checkers\n",
    "- Build the general architecture of a Neural Network Model consisting of fully connected layers.\n",
    "    - Initializing Parameters/Weights of each layer\n",
    "    - Implement the forward pass\n",
    "        - forward pass of fully connected layers\n",
    "        - forward pass of sigmoid activation function\n",
    "        - forward pass of tanh activation function\n",
    "        - forward pass of ReLU activation function\n",
    "    - Implement the backward pass to compute for gradients\n",
    "        - backward pass of fully connected layers\n",
    "        - backward pass of sigmoid activation function\n",
    "        - backward pass of tanh activation function\n",
    "        - backward pass of ReLU activation function\n",
    "    - Calculating the Cost/Loss/Objective Function\n",
    "    - Implement gradient descent to update the paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "# Fix the seed of the random number \n",
    "# generator so that your results will match ours\n",
    "np.random.seed(1)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Gradient\n",
    "We will be stacking multiple layers on top of one another to generate more complex hypothesis functions. Solving for the analytical gradients of each layer's parameters is no longer trivial and will be prone to errors. Fortunately, there is an easy way to compute gradients numerically. It is very slow to be used to train neural networks but it is very useful in debugging our analytically derived gradients.\n",
    "\n",
    "**Open `gradient_checker.py`, and implement `compute_numerical_gradient`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical Gradients\n",
      "[[-0.74692649]\n",
      " [ 0.54694129]\n",
      " [-0.76442224]\n",
      " [-0.2044723 ]\n",
      " [ 0.35616946]]\n",
      "Numerical Gradients\n",
      "[[-0.74692649]\n",
      " [ 0.54694129]\n",
      " [-0.76442224]\n",
      " [-0.2044723 ]\n",
      " [ 0.35616946]]\n",
      "Relative Error\n",
      "5.0943132806378086e-11\n"
     ]
    }
   ],
   "source": [
    "from gradient_checker import compute_numerical_gradient, relative_error\n",
    "np.random.seed(1)\n",
    "\n",
    "# creates a dummy loss function\n",
    "def dummy_loss_function(X, y, W):\n",
    "    N, D = X.shape\n",
    "    loss = 0.5 * np.mean((X.dot(W) - y)**2)\n",
    "    \n",
    "    grad = {}\n",
    "    grad['W'] = np.dot(X.T, X.dot(W) - y) / N\n",
    "    \n",
    "    return loss, grad\n",
    "\n",
    "X_dummy = np.random.randn(3,5)\n",
    "y_dummy = np.random.randn(3,1)\n",
    "W_dummy = np.random.randn(5,1)\n",
    "\n",
    "# solves for the analytical gradient.\n",
    "loss, grad = dummy_loss_function(X_dummy,y_dummy,W_dummy)\n",
    "\n",
    "# lambda functions are anonymous functions defined without a name. We use this to\n",
    "# pass in a function that has only W as its parameter and everything else is fixed. \n",
    "# Since the compute_numerical_gradient expects a function that outputs a scalar value,\n",
    "# we return only the first element which corresponds to the loss value\n",
    "numerical_gradients = compute_numerical_gradient(lambda W: dummy_loss_function(X_dummy, y_dummy, W)[0], W_dummy)\n",
    "\n",
    "print(\"Analytical Gradients\")\n",
    "print(grad['W'])\n",
    "\n",
    "print(\"Numerical Gradients\")\n",
    "print(numerical_gradients)\n",
    "\n",
    "print(\"Relative Error\")\n",
    "print(relative_error(grad['W'], numerical_gradients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check:**\n",
    "    \n",
    "Expected Output\n",
    "```\n",
    "Analytical Gradients\n",
    "[[-0.74692649]\n",
    " [ 0.54694129]\n",
    " [-0.76442224]\n",
    " [-0.2044723 ]\n",
    " [ 0.35616946]]\n",
    "Numerical Gradients\n",
    "[[-0.74692649]\n",
    " [ 0.54694129]\n",
    " [-0.76442224]\n",
    " [-0.2044723 ]\n",
    " [ 0.35616946]]\n",
    "Relative Error\n",
    "1.63980427129e-11\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "We will first use a toy dataset, so we can visualize our data and model's predictions in 2D. Below are two functions that generates circular data and spiral data, both of which are not linearly separable. We will use the circle data by default but feel free to experiment with the spiral data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dummy_circle_data(num_points):\n",
    "    r = np.random.uniform(0,2,num_points)\n",
    "    theta = np.random.uniform(0,2*np.pi,num_points)\n",
    "    inner_circle = np.array([r*np.sin(theta), r*np.cos(theta)]).T\n",
    "    \n",
    "    r = np.random.uniform(5,7,num_points)\n",
    "    theta = 2*np.pi*np.arange(num_points)/num_points\n",
    "    outer_circle = np.array([r*np.sin(theta), r*np.cos(theta)]).T\n",
    "\n",
    "    X = np.concatenate((inner_circle,outer_circle),axis=0)\n",
    "    y = np.concatenate((np.ones(num_points),np.zeros(num_points)),axis=0)\n",
    "    \n",
    "    randIdx = np.arange(X.shape[0])\n",
    "    np.random.shuffle(randIdx)\n",
    "    \n",
    "    X = X[randIdx]\n",
    "    y = y[randIdx].astype(int)\n",
    "    \n",
    "    return X, y\n",
    "    \n",
    "def generate_dummy_spiral_data(num_points, num_spiral):\n",
    "    r = np.random.uniform(-0.1, 0.1,num_points) + 5*np.arange(num_points)/num_points\n",
    "    theta = np.random.uniform(-0.1, 0.1,num_points) + 2*np.pi*1.25*np.arange(num_points)/num_points\n",
    "    spiral = np.array([r*np.sin(theta), r*np.cos(theta)]).T\n",
    "    y = np.ones(num_points)\n",
    "\n",
    "    for i in range(1,num_spiral+1):\n",
    "        r = np.random.uniform(-0.1, 0.1,num_points) + 5*np.arange(num_points)/num_points\n",
    "        theta = np.random.uniform(-0.1, 0.1,num_points) + 2*np.pi*1.25*np.arange(num_points)/num_points + 2*i*np.pi/num_spiral\n",
    "        tmp_spiral = np.array([r*np.sin(theta), r*np.cos(theta)]).T\n",
    "\n",
    "        spiral = np.concatenate((spiral,tmp_spiral),axis=0)\n",
    "        if i % 2 == 1:\n",
    "            y = np.concatenate((y,np.zeros(num_points)),axis=0)\n",
    "        else:\n",
    "            y = np.concatenate((y,np.ones(num_points)),axis=0)\n",
    "\n",
    "    randIdx = np.arange(spiral.shape[0])\n",
    "    np.random.shuffle(randIdx)\n",
    "\n",
    "    X = spiral[randIdx]\n",
    "    y = y[randIdx].astype(int)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x21564199b38>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsnXd80+X2x9/PN6sj3S2UVfaeAjIUcYEiijgg6nXg3uC67uu66k+veN1brooTg4MhCgIqCLL3KrJp6d5t2qYZz++P0JEmXTRpUvi+Xy9f0u96TpJvTp7vec75HCGlREVFRUXl5EEJtAEqKioqKr5FdewqKioqJxmqY1dRUVE5yVAdu4qKispJhurYVVRUVE4yVMeuoqKicpKhOnYVFRWVkwzVsauoqKicZKiOXUVFReUkQxugcdVyVxV/IwI0rnpvq/ibBu/tQDl20tLS/Hr9+Ph4cnJy/DpGS6G+lqbRvn17v16/Ibzd28H0GQaLLcFiBwSPLQ3Z0dh7Ww3FqKioqJxkqI5dRUVF5SRDdewqKioqJxmqY1dRUVE5yVAdu4qKispJRsCyYlTccdgdzH9jCXvW7EMIweDz+jPxrvMQIlBZeyoqLYGdUOZjEBuQhGCRV2OnT6CNavWojj1IeP/ez9n0yzacDlca9IHNh8k8nM3Nr1zdpOtsW76bJbP+wFpqpU2XeK556jIi4yP8YbKKSvOQkmjxFAbWI4QDAD1bKZZ3Us6EABvXulEdexCQfTSXvWv2Vzl1AHuFg50rkinJtxAfHw/Aoe0pfD9zEcU5xYRFhXHpjAvoe0bPqnPWzN/El099T0meBYD9mw6TsjuNp+bfjyHM0LIvSkWlIewb0bOtyqkDaEQBRj7CKWMI4U+cGCllKk7iAmho60N17EHAsb8zKMot8dhenFtCTmoeXXp2JuNgFm/f9j9yj+VX7U/7O4N7P7qJnsO7AbDsk5VVTr2SlOQ0ln32JxffPc6/L0JFpYkI22oUUeqxXUMeMeJRKqOQIfJ3SqQJo5iLQj4gsNGLQvkvnLRpWaNbCeriaRDQeUBHYhKjPLZHtY2kbdcEAOa9scTNqQMUZBWx8O2lVX9bCj2/JEg4uvuYbw0+xTCZTBqTybTFZDL9FGhbTiqUzkjp6YKEgJpLS1qRSZR4B63IQBFWFFGOQWwnXlxHCL+0oMGtB3XG7kcyD2WTvHY/nQd0pMvATnUeF5MYxeDz+7P6+w3Yym0AhIQbGHHJEEKNIQCUeJnRA5QWllX9OzI+gvT9WW77Fa1C75Hdm/tSTnXuA/YAkYE2pHUhMfAXIeJXpNRTigk7PQFJBG+hlK5CCGejriSEpwSPIiqIYiZGPsNBW0rlFKycRThfYhBrENhwSh1SxGKXnbBwDfIU+QhVx+4HpJR8fP9XbP9jD8W5JYRFhtJ9aGdmzLoVfYjO6zk3vmyi5/AurFu4FaEIxppGMnzi4Kr97Xq2ZceKZI/z4jrGVP178v0T+Pj+L8nPKKza1m1wEmOvGuXDV3dqYTKZOgIXAy8CDwbYnFZFBK8RKpaiiHIQYJB/4SQRiQYtBxHYmz2GEE60ZB7/7yhWuZQQsQ5FVBw/gKr/h8jlFMgXsNOr2eMGO6pj9wOr5q5n3cIt2CtcN25pURk7/khm7ssLufbZK7yeI4RgzNSRjJk60uv+yx6YQPJf+93CKu16tOWqJy6t+rv/mF48/PXdLHjrV0oLS+k6OImL7xmHVq9+zM3gDeARQE0tagIa0gkRq1xOvXKbsKDhQJOvJaV7aKbOMUUBIayvduq10IosYpmORV6HheubbEdrQv3G+4ENP2+rcuo1ObjlyAlfMzwqjCd+mMHP7y0ndW86bTrHM2n6eIwx4W7HdeiVyF3v3HDC46hUYzKZLgGyzGbzJpPJdE49x90O3A5gNpursphqotVqvW4PBH61RToR5bNQyuchZH7Dx9d1GQA0oLTHqRmAYluPILfB82pm2HhDEVaMylxCjeeCbkjV9mD5fHxlh+rY/YBWp/G6XdF6395YQo0hXPnIxc26Rm2S1x5g2WcrcdqdnHHlcIZNGKQWRVVzJnCpyWSaCIQAkSaT6Uuz2XxdzYPMZvNHwEfH/5TeZFeDRRYW/GtLBDMJE0sQonlhFgFY5WDy7a+BHTQcw8j7GMQ6BLY6Z/BOGYJGeF+Pqrq2LMJe9CYFcmbVtmD5fHwl26s6dj8wbtoYkv/a75alojNoGXbhwABa5cmid5ex6P1lWApcC7A7ViYzZsoIpv3f1ABbFhyYzebHgccBjs/Y/1nbqatUIyjCIDY22alLKbwujgqsVf920IFCXgBpJ4SlGNiAjl1oyKo61ya7YpWnE85cr9eriZ6dCEqRhDXJ1taCTxy7yWSKBmYBA3A9Rd1sNpvX+OLarZF+Y3pzyb3jWPntOopyigmPCmPwuP5ceNs5LWqHpbCUNfM2odFqGH3ZMELCq4uUKsptrPx2bZVTB6gorWDzkh1Mmj6e2HbRLWqrSutCy26M4nMUinASi012xyDWoCHL6/EOGYZCqcdMW0oNVjkcA+s89tllkteRy7mIcnkRYCWM+ejYjV12phQTkeLVBp06gKCMUBZRysk5ifHVjP1NYLHZbJ5iMpn0cHL+DDqdTo7uOoaiUejUt329IYuJd53PBbecTW5aAdFtIlq88nPNjxv57pVF5KTkAfDz+8u54YUpDDynLwBZh7MpyCryOK8gs5B9Gw8xctJpLWpvsGM2m/8A/giwGUGBlt1Ei2fQiuyqbQZW1Rkecch4cuX7GPmQUH53i4Pb6EMBTxPL4+jkboSwI6WCne4Uc2cDlhgoxeTWjLDmLL8+hABFZgFOQliCUriAGKGlQo7CwhSgdVdqN9uxm0ymSGAscCOA2WyuALwvS7diDmw5wqePzCHzcA5CESR2S+DOt66nfc/EOs/R6rW07XJiCyFSSua/vpiNi7djK7MTnRjJVf+aTLfB3mYx7lSUVTDv9cVVTh0g63AOc16YT/+zeqNoFGLaRWOMDqO8xP2LEB4dSodedb8mlVObMOZiFJ+hCPcK57pj3gbK5WicJFDEvyiVl2FkDoIytCGDyS+bCoSSJ18jhOUY2ESF7EMZF3MizrVcnoOeDSjCVu9xThlJOWcTK25DxwGEAwwC9OzAwGry5OsnNH6w4IsZezcgG/jUZDINBjYB95nNZrdPvjGZA77El6vcDoeT2Y/OJGVPdS/LIztS+eSfc3h91fMeM/ei3GJKi8po2yXhhBci57z0I4ve/42KMtdvZMahLD6c/gWvrfw3UQ2Iem1eup3Mw54LMLmp+Viyyuk6MIn4eBh6/iB++3o1dlt1TLTPyF4MOdN/awHBkn2g0nRCmYdRfOpVBsAbNtmJEnkjVs6r2mZnAAXyBQDiw+ORZZX3qZZyLqRcXtgsG8sZj4EN6OV6NKIQpwzFThIKJWhIQwiJU0ZQJs8nlKXohXv6pRCgk7sJY0GrDtP4wrFrgaHAdLPZvM5kMr0JPAY8VfOgxmQO+BJfrnLvXbefY/vSPbYf25fOjrW7qmbt1lIr79/7OYd3pGIrtxHbPhrTk5cycGzTZUj//GFtlVOvJONgFl+//B1TH5tU77k2bOhCdFSUup+v0Wsot5VVvS/XPH8ZYXGh7PgjGel00n1oF656crJfswNOhWbWJyuuYqPGOXWnNFAon8BOXz9bVRtBoXwSDUfRy43Y6YGNgQjKCeUnFJlFOROw051YcY/3KwjQsRNk63XsvtCKSQVSzWbzuuN/f4fL0Z80SOn6z2M77ttnPfg1W37dSX56ASX5Fo7uOsbsx8zeNVxqUFZSTmlRmds2a6n3aFZeWkGD9nYbkkT7Hm09tnfs1Y6EpGqVPEVRuPzBi3h6wQM88f19tOvRltlPmNn48zaczsaVequcOgjKGj7oOJLwADj1ahwkUcYV2BgECCShlDKVEu7BTvfjNurrPF/K5qUmB5pmz9jNZnOGyWRKMZlMvc1m817gfGB3800LHnoO70pi9zYc2+s+a2/bOYH2PV0O1GF3cHhHise52UdzWfHNGibeeb7HvpJ8Cx/M+IJje9ORUtK2SwK3vv4PEjrGEdcxlvQD7hkGhlA9oya7fjOP7j7G968soii3hIiYcC7/50S6DnLp0QghmP7xzXx8/1dkHs5GCEGHXonc8Zb3arvivBJeueY9UpPTcDoka+dvpufwrjz0+R1q1apKFQ4S0XGwUcfaWkHZfrkcj46dXuPxOnH4+KytddZ0+OpbOx346nhGzEHgJh9dNyjQaDXc9B8Tnz1mJvNQNkKjkNg1gdtev7Yqhi6d0k1PvSZlJd5X6t+581P2rN5X9Xd+eiHv3P4pzy56iOufv5I3bp5F+v5MAAxhegad149B5/Uj/UAmb978MTmp1ZV9KclpPDD7DpL6usIQ8R1ieXzudCyFpSiKQmhESJ2v7+tnf+TormqpAlu5jT1/7WPZZ38y4fZzG/kuqZzsFMl70bPZTSbAG05poExe0EJWnThlTEQv1xMq/vDYpyEHDek4aJ1hPZ84drPZvBUY7otrBSs9h3fj+SWPcGh7CopGocvAjm4Lo1q9ljZd4slJzXM7L7ptJOf8Y7TH9XKP5ZGa7Bm3T9uXyf7Nh+k5rCvPLnqI5bP/pCCtmCET+tPvzJ4IIfjxtcVuTh1cIZr5r//C9I9ucdseHtVw5mnGIc/cY+mU7Plrn+rYVQAIZQGh4ickRqS0AQ6EqAxFKoAGsOGgLVY5Biut474pYyIGuQrFo6jKSrR4GIHAThJF8mGcxHi9RjCiPmc3AUWj0P20znXuv+W/1/DWLbNI25eJzWonrmMM428aS1x7zxuirLgcm9XzEbCivAJLgSsmHxJu4OK7x3ksOBbneC+ZLq7VZKOx6EO8xxrDIkNP6HoqJweCAsIxo2UnerEPRVTH2J0yFKscTJkcj5XRKJSiIQ07nZF49hYIVioYhoPOKLXEyQRWdML1FKslFYUnyJPv0VpCM6pjr8XhHSnMeX4eeWkFGMINDLtoEJPvu7BRaYvxHWJ59ud/snvVPgoyCxkyrr+HSFcl7XslEt8pjtQaKZQAbbvEu7W780ZCUiys9twe1yG2QRu9cfY1ozm665jbAm5020gumT7+hK5XlFOMRqdp1NOCSnCiZSfR4kW0wvOpEkARZUgZghXX2pGTMJy0xjRWDQXyWeK0byDtR5AIFAo9FCJ1JGPkPUrwnkkTbKiOvQYl+RbeveszsmrkgGcczEJRFC6d0biYoaIoDBjbu1HHXf3UZL54Ym5Vznl8x1guve9CDKF1r9YDTHn0EvZtPEzavoyqbe26t2HqY5c0ysbanHHFcEqLSvnz23VYCsuISojg0vsuoEM9xVfeSElO47NHvyU7JReNRkPHvu258+3rVQffCokU79fp1CtpSpZMMOOgE86o2eTmHEIhkzjxALVrLIWQhLEAm+zrlpcfrKiOvQaLP/7dzakDVJTZ2PjztkY79qYwcGwf/r3kEdbM24Tdamf05cPqnOHXJDI+gid/mMH8N5aQeTibhE5xTH5gApFxxhO2ZdyNYxl349hGH1+QWUjKnjTa92xLXIdY7DYH798zm2N7q39s8tIL+ODez3noi4ZKw1WCCzsK2fUeIaXAJge1kD0tgyQCB2E4SECh2GO/IqyEsRCrVB17q6J2T9FK6sop90a5xYpWr61Turc2IeEGzr32jEZfvxJjTDjXPue9aUdNDm07yqJ3l1FWUk7XIUlMmn5Bg08E9SGl5NNHv2X7b7vJzygkKiGCvmf25PSJg8k44LkIm5KcRkm+pVE/WCrBggaJ5/pKZcMLp9Rjoz+WVlyZWTcaSuQ0onkR4aVhh6D+jKBgQXXsNRg56TQ2/bwda62Kz/iODa+GH9x2lK+e+YG8Y/noDFp6jezOjS9f1WgH7w82L9nBZ499S2G2a/axc+Vektcc4PG596I5QW34lXPW8tf3G7BZXVkEhdnFbPhpKzarHYfds6jJYXNSUWajFSUUnIJIwplNiPgTQSlOErDJ7mg55ibB6yCOCucIrIzCyln4pr4x+LByNiVyP0a+8KI4WXfv4mBCdew1GHx+f/qP7c2OlcnYylwZK4nd2zQ4My4rKefD6Z+TcbD68TXraC6KIrh55jUex0sp2f7HHrb8upOkfu05yzQKncH3H8Wi95ZVOfVKDm49wtp5mzlzyumNuka5xYqlwEJMu2gURWHDoq1VTr0Sh91JUU4R8Z1i3YTHwNWTNaZd68mSOBUJ5yvCxTcoorLeIh0tesrlILQUIKjAQXuK5P2tNq+7qVi4AT070UlXAZNLcbIbxdwdaNMaherYj7NzZTI/vPoz+RmFRMSEE5oUwqjJQxl/09n1FvcArPh6rZtTB1ce+N51B3E6nShK9czG6XDyxk0fk7xmP9ayChSN4LcvVvPwV3cRleDbDupFuZ5pkQ6bg12r9jbo2J0OJ58+8i171uyjvMRKdNtILr5nXJ3ZQVqdlkn3jmfB27+Sm5qPohG07daGaf9nUjsyBTkGsbKGU3ehiApC2Eo551Ion6rjzJMZHfnyVQyswCDXY6M3ZUyktSg+ntKOPeNgFslrDxDTNorZT5jdYuxagxanQzbo1AEKswu9brdZbTgdkhp+nT+/XcfOlclVYQunQ5KyO40vn/6Be96/sVmvpzbG6HCycF8MVrQKPYZ1bfDcOS/OZ9X363Eet7M4r4Q5z8/jojvPY++6A27rDlq9liHjB3DOtWcwfOJgNizaSogxhOEXDfbLk4iKb6lroVQIJ3q5EQ2HcdClZY0KCjRYOa9WFoyTUH4kTPyEQ7ajkH8iObE0Y39ySn7rpJR8dN+X7Fixh+JcCxqdBofNvQmu3Wpn69KdXPbAhAavd9ZVI1n57TpKahUIJSTFecTYt/62y2ssOvNQ/VkIJ8L508aQdTTHza6kfh0Ye9XIBs/ds3pflVOvpCCziIyD2Zx73ZlsWrydgsxCIuMjGHRuXy689RzAtah77nVner1mxsEsvn7qR/KzCxh12TCGXjhQnc0HAYK6W9lpRCF6uYWyU9Kx18ZBvLgWDRkIAVoO0QYTefJFbDT8nWpJTknH/qd5Het/2oq9wnVD13bqlVSU1y/WX0n7HomcffUoVn67juLcEoQiaNe9DTe8OMXjWGOU9+wQfaiukdY3njFTRxARa2TppyuwllbQvlcipscmNUrYy2H3/p6UW6zc+JKJyfdfSOahbBKS4hqV8bL+py189cwPFGS6ujZtXb6L0y8Zwu2vqy1EA42Ddmi8pPeBq6WdjfoL5k4VwvimyqlDZXMRO9G8SLZcEEjTPDglHfvGX7ZXOfX6aNs1wev2XX/uZcmsP6gos9HttCQm3z8B0xOXcvY1o/nrhw3Eto9h9OXD0Yd4OutLpo9jx8pk8tOr5XdDjAZGX+4fqZ3B5/dj8Pn9mnxeh56JbjnpAKERIZxzjUv3JiwylK6N6OYEriekn95ZVuXUwVUfsG3ZblL2HKNT3w5Ntk/Fd1TIwej420s/UrDTBzv9A2NYkBEmFnvtFOXKeXfg0ssJDk5Jx15XCqLQCKRDomgUOvRK5IYXPfN0V8xZi/nF+ZTku/Rc9vy1j30bD/H43Om07ZrA5Q9NrHfstl0SuGXm1cx7fTEFmUWERYYw+vLhnH/DmOa/MB8y7SUTuWn5pO5Jx1pWQVSbCEZMGkqf0T2afC1LQSmF2Z79VUvyLWz5dafq2AOGRCGTUq5Ax0F0cg+KKEVKDU7CKZfnH+87qobLABwyEq3Xt0ICVoKp1fMp6djHTRvDnr/2UVpYXRKtD9Fx9rVnoNVpaN+zLWdcPtxryOK32X9WOfVKDm1LYfPiHQyfOLhR4w88py8Dz+mLlDLgMWYpJfs2HGTfxsP0Gd2jSuTMGBPOU/MfYPfqfaQfyOS0cf1PWIsmxBhCiDEEMt2du86gpWOfUyN9LtjQcJAoMRMNLqErO0kUyKfQyDQqGILjeDMKlWrKuAS93O111h4jHiVfvt3yRtXBKenY+43pzaR7x7Py23UU5RRjjA5j8Pn9+cezl9fraB12h1cFRVu5jeS1+xvt2CsJtFO3We28cdNH7N98mPISK6GRofQe0Y0Zs25Bo9UghKD/mF70H9O8pglanYbB5/YjJzUPe40c+I592jNkvPqY3+LYDxAj/oVWVAvQadiJhlfJkd+hztC9Y6M/EgMC99RQV5/UZHRsxhYkzeNOSccOMPGu87nglrPJSy8gqk1ko8rsNVoNxphwD+kBnUFLrxGtb4bz42u/sPPPva4nSaCsqIztv+/mlw9/55J7xvl0rGueuYywqFB2rdhLWWk57XsmcsMLU9xy/FX8i6CAaPE0mqIDgOcERUMu4XyKhZtb3rhWgIPO2OiNge0e+xRhI5pnyJcvYWdAAKyrZU+gDQgkWr2WNp3jm6Sdct4NYzyyQLoOTmL4xNYniLR/0+Eqp16J0yHZs/pvn48lhOCyBybw+qrneeHXR7n73WmqfkwLEy3+D4PYjsDiNZwgBBjEhpY3rBVRIF/AKb3ftxpRTKT4oIUt8s4pO2M/Uc75x2jiOsSw9JMVWMtsdB3UicsfuqhVzjw1Wu82a9Q+pych5Wg40uBREt+n3Z5MSCKxSNNxHRnPzDqFTFwLqYGtUFW/wSfAwLP7MPDsPoE2o9mcZRrBwa1HKK/RkzUsMpTzrvdeYKTSehFIPB7PaiElVMjTWsagVoyFaWhkJqH87OXJR4Mr9TGwnFKOPfNQNr9/9RfhUaGce92Zp3wo4IwrTic7JY+18zZhKSjFGBvOWVeNZMj5LbegKaVk85IdrJ2/mfDoMC65ZxzxHYOvRLu1IwnFQRJaPKWVq48Jx8L1LWhV66WI+9CxGx2Hq7ZJCQq5xIvbKZPnY+GmgNnnM8duMpk0wEbgmNlsPrFWPn5k/ptLWPbpnxTluCrsVnyzlhtfNjFgbOufeTeHyfddyMV3j8NS4NJMP1E53xPlwxlfsGnxdpe0L7Bt2S6mvWxq0R+XU4VC+TjRPI1O7PUqI2CnK6fYXK8ZGCiQLxLJ62jZh0IhQoDAhkIqYczFLrtjpfHNa3yJLwPD9wF7fHg9n1GYXcTvX/5V5dQBso/mYv6/hUhZ/+PpqYBWpyEqIbLFnfqhbUfZtnx3lVMHV9elea8vVj8XP+Akjjz5Dg7j+ziku5SyQxoplfUX16m446AD+fJV7HTzCMloRCmh4ufAGIaPHLvJZOoIXAzM8sX1fM36hVvcSvgryUsvID/dpcxos9pZM28Ty2b/SXGep9ytiu/Z+PM2twbalRRkFlFR1viuVSqNR88WNGUzEZS7KkylgQrZixJ5B+Wojv3E8BT1g8D2hPXVc9cbwCNAhI+u5xP2bTzIty8sIP2g97iiPkRHaEQIR3am8sH0L8g4mIXT4eTn95Zz0Z3nMf6mwDxGnSp06N3Oq7JmqNGAzqBmZ/ieciLFawhHarWQFQ6kNFLGpMCa1oqpkIPRsx0hqp8ypQQdfxMjHqZAPodsYbmBZjt2k8l0CZBlNps3mUymc+o57nbgdgCz2Ux8fHxzh66X0qJyZj3wDRmH6l4s6juqF526duSNaR+Ttq9a8Cr3WD5LPvyDiTeNJyo+8L9VWq3W7+9XS1HztUy8aRzL/reSA9uq0/D0ITpGX3o6bdq2CZSJJy0hrKySEKiJlqMIipD4ttHLqYKFG9BxAL3chiJcT/uueHsZBjYQySsUymdb1CZfzNjPBC41mUwTgRAg0mQyfWk2m930WM1m80fAR8f/lDk5OfiTJR+s8OrUNVqF+KQ4up/WhWn/mcrBvYdJP+x5XHZqLr/MXsa4aWf51c7GEB8fj7/fr8Zgs9opKyknIja8XjmEo7uPsXnJDjr2acfQCwaiaKojfrVfy32f3crnT8wl41A2OoOO0y4YwKQZ45r1etu3V/VnaqMlmRAW4z3lUVJXOEGlMWgpkC8SwX8JFws99urYh+s9bjmphmY7drPZ/DjwOMDxGfs/azv1QJCblu91e2yHGP6z4skqx+SwOdB4UXtUNArhUcGj1hZInE4nXz71PTtX7qXcUk50mygunXGBhzaOlJKP7v+Sbct3YSkoQ6vX0qlvOx764k4iYo1erx2VEMn0j29piZdxiuIgWjyEga0I4QoR1MZOeyTRLW/aSYbE+z3u+tFsWcfe+solG8n4aWcTGunZ1q5t53i32WZoRAid+3nKxiZ2S2D4RU0T9TpZ+WHmz6z4eg2Zh7IpzCrmyM5Uvnz6e7JTct2O27xkBxt/3oalwLVoZK+wc2hbCl/867tAmK0ChPFjlVMHqv4vJTilngrZiyL5eOAMPE5xXgmfPjqHl696h3fu+ISU5LSGTwoySrkMh4zz2O5KI21ZV+vT0cxm8x/BksPed2RPRl06lPBo16xb0Qg69Erkei9dje5463pOu2AgcR1iiGoTSfehnbnz7RvUfp3H2f5HMvZaC5z5GYX8/N5yt21r5292S12sJG1/pl/tU6kbg1jmVRcGwCKvJk9+iIPAhq4shaW8NPUd/vhqDXtW72PDom28dv2H7N94KKB2NRUnbSmR12KX7Y7/cIZSIftTKB9pcVtOas9148tXcf60Mfz1wybadI7jzCkjvHY1Co0I4f5PbqWsuByb1UZkECyYBhP2Cu8tAkuL3dO5Qo3e9TEa04pPxT+IemQEnEQQDBK9P7+3nGN709225aUX8OPri3n4q7sCZNWJUcYVlMsJ6NiBk1js9CAQ7/FJ/43r1LcDVz3ZuA49oREhhEZ4hm9Oddp1b+vRJs8Qpuesqe4NfC++exzbft9DQUZh1TatQetRRWopLGX9T1vR6TWcfslpTVLXVGkaxfIGYnnSs+0dCuVcEBijalHXE11xXglSSrb/tps18zYRkxjNRXeeR2ScK5Z9ZFcqq+auJ75DLGf/YzQh4YEV3qpEEkZFVXNrK3p24MSInd60lJM/6R27SvOZ9pKJ3NQ8UpLTsVfYMcaGM+zCgfQf29vtuLZdE7juuStY+M5SCrOKCTUaGHR+fybff2HVMb99vYrZz3xLTkoeCFjw9lJu/s9V9BmtNkz2BzbOxCqHuMXZJYIyeRGSqPpPbiHadPGeylsEtmNFAAAgAElEQVSSb+HRs18kLy0fW7lLAmHDoq3c+c4NrP5uA+sWbKpaz/nty9Xc/J+r6Do4CX2QTBQM/E6E+B8a0pDoj3epeg4n7fw+tghQ6bZMS/Pv4kiwpAj6gmB4LU6nk63LdpG2L5NhEwbSrnvbOo+VUlJaWIYh3ODWX9ZaVsGzF/2XtP3us/+kfh14bvE/2bfhEMs/X4UAzpt2Fr1HdDshW4+nOzZ7amQymToBnwOJuFIbPjKbzW82cJrXezsQn6GgBAN/4cSIk0iMfAYoaCNnkFPUsUVt8UZ8fDzLvv2D/z00x03uA0AoAun07ps6D+hATkoelkL3UKBGpyG2XTQ9T+/GLTOvblII0Nefj6CEOHEbWuEeYrLKweTLum+hhuxo7L2tzthVGoWiKAy9YCBDLxjY4LFCiKpF65rsXvU36QcyPLbnpObxxb++Y+28zVUSA9t/38OE289h8v0Tmm/8iWMHHjKbzZtNJlMEsMlkMi01m827A2lUYwhhEUbxJVqRjpRa7HSiQD6Dgy7E6+OBwEwUinJL+PaF+WQcyiI/rYi8jHyvDrwupw6QsjsNp5f9DpuD7KO5ZKfkotVpuOXVa3xqe1MI4XcPpw6g5VCLFIOdco7dXmFn3cIt5GcUMmryUFUitgUJjQhBZ9BRUe6+GKvRadi6dJebbkxpURmr5m7gglvPIdQYmHUPs9mcDqQf/3exyWTaA3QAgtqxC4owis/RClfsWgg7Og4RxavkyXda3J49a/ax8O2llORZyDyc7ab/fyJ4c+puSFgzbyPSKTE9eWlVTL4lkWiQUrjJDAAoFBEl/k2BnIk/4+2t2rFbCkv55cPfyDiYTe8R3Tnn2jPqTVHMOJjFW7f9j/T9Lk2YX2f9wVlXjWLqY0GRoXnS02tENzr2ac/Bre6dfGIToziy27PUPedYHqnJ6fQc3rWlTKwTk8nUBTgNWOdlX4NyGS0pCyHKl6Mp9VyQ1CkZxEcpLWrL9hW7+Wj6l+RleIrw+RNbuZ0/zetI3ZPOK789TVhEaL3H+/w9kVOg4FOQ2W6bhQADm0iI2ILUey5e+8qOVuvYs1Nz+e91H5J+fEV90y/bWLdgM498c7fb4kl+RiFLP1lBhdXGwS1H3LI7CrOLWfH1X4wxjaBdN1WbxN8oisJjX83g1ZveJetIDkJR6NAzkamPX8J/r/+Aohx3Vc2I2HDi2scEyNpqTCaTEfgeuN9sNhfV3t8YuYyWjLGH4CRKeM4WpbOY3Lwi4uJjW8yWr/7vO7859cg2EShCUJhdXGfo5tCOo3z98vdc9kD9IT1/fD4xohMGke2xXSCpKJ5HoRzaZDsaK5fRah37nH/Pr3Lq4GrCvG/TIZbMWsGk6eMBWDN/E+YXF5CX5rqxhOL56FOcZ2HF12u4+l+TW8bwU5wO3RN58of7KMm3IBRRJdvQY1hXNv+6o1rKRLi2xbYPbKm7yWTS4XLqX5nN5h8CakwjKWcskcxE4C59LLCjIQXo4tfxc4/lsWTWChx2B/k1Ul+bgjEm7Pg6jcBSYKEkv9Rtf0i4gbvemUafkd357pVFrPxmDcV5Fq/XClQVq032xiA2e92nlQf8Onardew5qXmeGyUc2HwYAIfdwcI3f61y6lD3gkxUfMvH4E51arclvPu9G/nm+Xkc2HQYBPQc3jXgP7Ymk0kA/wP2mM3m1wJqTJOQOAlFqe3YhYMQuRLwn7Ddijlr+eHVn91qGepD0SgYwvRIKVE0CtFtIunQux03vmTCGBOOlJJD21N4/57ZZB12zWT1YXoGndePvqN7IITA9PgkDGF6fpjpvbFFYtcEn72+pmDhKsLkjyii3GOfVmSD9F/T61br2OtaUIs4vlCS+nc6eenehcBq0rZLPOdcqzZvDjQ6g5YbXvCUewgwZwLXAztMJtPW49ueMJvNgWuN0wgEFSh4OhMpNdjp7rdxbVY7v3zwW4NOPSLeSKfe7YhrF8u428ZijAojIs7otVBNCEG3wUk8s/BBFn/0O7lp+Yy+fDgDz+7jpvnUdVAntDqNh/SFVqfhglvP8cnrazoGJCHg5bMAG1oOHy9a8j2t1rGPv3ksKclplNR4/IrrGFNVDBMRa8QQFkJZsfsKvKJRiEqIQEpJXPsYrnnmMrXaVMUrZrN5FcFQc99EIsVbKMIz88RBIuWcU6cGYXNJ3ZtOTmpunfsj442MvXoUl9wzntCIkCbFtY0x4Ux5tO4khwFn96Fj3/Yc3p7itn3ohEGER4WxYs5adq3cS5sucVx0+3le03F9TTifoRF1rS9IBM3LDqqPVuvYh00YhM1qY/lnqygtKiOqTQRXPnJJVfpibGI0XQd1YstS99lDtyFJPDLnHuxWe4t8uCr1s2TWH6xfuIWKsgradEng+hemEN1GbfjQHHTs9Lrd382qI+PCCTWGYCv33lqyY5/2TH3MP52aFEXhwdm38+mj35K+PxONTkvvkd246l+XMfMf7/H3hoM47S7N+Y2LtvHAZ7fT1s8hGp34u859DuKw0ctvY7daxw4wavIwRk0eVuf+u96bxmePfsvBrUdwOiUderXjllevxhCqV/VJgoAFb/3KT+8sxVrqigUf3Z1G5uFsnln4kKqs2QwUvM8ShfRvD864DrF0GdiJ7b9772nv77TVqIRI7v/kNrdtsx76muQ1+922pR/I4tXrPuCJ72cQk+g/WQVZR/xcSg2l8mpcfYn8Q1B/e0ryLSx461cyD2aT0DmOS++70Guxwcpv17JyzlqslgriOsbyj2cvIz4+HkOonjveuh5wlbnX1/VHpeVZv3BLlVOv5NjfGaz+bj3nXHtGgKxq7TiRdahxO/ysDbP4w98pyikhxGjAarFWNfXQhWjpMbQrl9w73q/j1yY/o5C1871npWQdyeHfl77Gtc9e4dEwxleUyivRsQeNqI4aOKWeQnkfVi72y5iVBK1jL8ot4WXT22555ztXJvPIN/cQ2646Be63z1cz9+WFVVWLR3cfI+NgFm+ufsHteqpTDy6cTqdbpWnVdruTo16KlVQai4KTdmhwT6eTUlDBcL+Nuuj95cx/fQnW0uq4cXRiFMMuHMjAc/oy+Px+KErLNptYMusPbOXeJacB8tIKmPfGYoZOaFgm40So4HSK5Z2E8SMaCnEQTam8DCsX+WW8mgRtB6UfZi7ykIpN35/F3Jd/ctv2p3mdh4NI35/J/HcX+91GlRNHURSvj8H6EB3dh3YOgEUnB1r+xia74JDulZZ2evlVpnf9gi1uTh2gIKOQqIRIThs/oMWdOuDxNOiN/PRCclMbzp47Ucq5iDz5EdnyG/Lkh5S3gFOHIHbslTmrtcmtlb9eVuI9bpj6t6cAj0pwcdmDF7k9fQHYKux89eyPvGR6m5J87wUnKt6wEiMeIlY8QJiyHIGCXcZRIftQ6pxAnpyJvx7QpZQU5ngU5AKQediz8rKlOH/aGIyx4fUeYwjTExZVv9yAb2jFrfF8ibEO4R5jjHsmS3Qbz1mfRqdh+Hi1X2mwM/DsPjz+/XTOnHI6+lBXZyvplFjyS0n+az8fP/BVgC1sPUTwPno2oQjXj6EiLCiUYJHXUMRjflMTLMgq4olzXyI/3TN3XRei81v8ujF07N2O8TeNrape9qg8F9BjWJeTsml90Dr2yx+cQFxHd52Q2HbRHjKuUx+fRHynaoVGRaPQe2R3zr5aXXxrDbRJiqdTn3Zee6WmJqdjs9oDYFXrQyeSPbokKcJKqFjq13HfufOTOjsgDTirN0PG9fe6r6W47IEJPPfLw9zx1nVMn3ULp43vT9uuCbTv2Zazpo6k/1m9mPf6YtK8yEm3ZoJ28bRd97bcN+tWvp+5iOLcEoyx4Uy+fwKdB7g3COh+Wmee/OE+fnpnKYVZRfQf25uxV49Gowna3yyVWjgc3qUeJJIANYJphWi8bpV49vj1FVJKDm456nWfolW47Y1rAxJbr01knJEzrjgdgGHH+wlkHMrirVv+x+rvN+B0OPnt89WMvmIY1zx1mV9tUUgnWjyJllQE4CCeAvkv7PTz6TjNduwn2GWmUXQe0JEHZ9/R4HGx7aK54cWpvhhSJQCMvXoUyz9fRd4x90Wsdt3bem0+ruKJVY5Ax16EqH7CccoILPJKv47rdDi975Cu3gfBymePmTn2d02l1yJWmdczZuoIOvVpnIJi0yknVtyLVlRX52pJI5ZHyJGf4MR3CrO++Dmt7DLTFxgF3GMymXz786NyUhMZZ+SKf15EYtcEhCIIMRroPrQzt79xbaBNazWUchk22R2nDMUpQ7DJJErk9dgZ4LcxhRAYwrwX+hljwolKCM4KYqfTSfZRT+mDknwLK79Z67dxw1iABs9xFVFCOL5dT2r2jL21dplRCS7OmjqSkZecxv7NhzHGhNOpb3u19qCRaNlHtHgOrUgFwClDsNOTUvz3FFtaVMZ7d3/mVTFVUQR3vHWd38ZuLkKIOvuhRiVE+G1cLYc91kEq0Yi8aslqn4zlQ+rrMqPSGCSemlN2ROn7xIjVgEK5PI8yLvZyXOtHH6qn35n+0884WYkQ71Y5dQBFlGOQa9CxHRv+yUr56L4v2PFHsts2ISAhKY6bXrk6qD9HIQR9RvUg81C22w9Tm87xnHu9/5ReyzmbULkYIdzDV1KCVdYtjXIi+MyxN9RlpjHtw5qDtayCvRv2ExlrpHP/Ti3a/qupCOs8hPUHhNOCVBKRIgbFsQNkOVLTAWfY46DtCYBSfB9K+R9ohEuOVC/2YAzJQ4Y+gCj/H0rFH4ANp6YvMvwREMGduqXVagkzhPPjG4s4tDOFpL4dmfLgxYRFBrfdwYwGz6wURZQSKpf5xbFbS60c3ePZvEICF98zPqideiXXvzAFp8PJ3rX7qSi30SYpgamPX+zX1McKRmDlNAxyU9XMXUqw0YsyfNue0yeOvTFdZhrTPuxEWTV3PQvf/pWswzkYwvR06NOe5354GLtSdzlxoAhhEZHiAxRRDIBw7kVKqj5oYT+Gs3AGufJDFDKJExtAVGtMC8qQZUuwluYQKhYjhKu6TuPYhdW6n3z5OsE8mzcoITwy7jmO7nY5hjXzN7J63joe/fZenzUdbmz7sJMF6UVMSkpw0M4v49ltjiqlxFqGYLX4T4rWl2h1Gm559RqyjuaQsjuNfqf3ISTW3wv1ggI5EwO/YmQOgmIkBgSSaPE0xfIuwDeTUV9kxQS0y0xRTjHfz1xU1SmprMTK/o2HeO3WD5nxyc0tbU6DhIlFVU69ktpxNw0phPITTiJRhGdFn0IBBrEWRbiXTOvY69fHb1/w+bPmKqdeSWpyOt+9vJCbZ14TIKtaN1Z5BhqOud0PDjpRin9S98KjwmjTOd6j7V1MYhRnXOk/PRpf4rA7+GD6F2xdtpOKMhtCERhjwpj2fyZOv3iIH0dWsDIBZAhR4lWU4xkyOvah5Qg4v/HJKL6YsQe0y8zKOWvd2t9VkpJ8DJvVHnTyr4KGy+SFAI1Mx8oopNQghKPWEU6El64siihDKw8EtWOvmWJWk8xDrie4fRsPMu/1JZTkW4iIM3LFQxfRbYiqHVMfJdwKUhDCL2goAgRODOjYQQUj/TLmpBnj2Xf9QZw1YtQOu6Ne0a1gYt5ri1n/05aqBUvplBTnWvj00W/pMqgTCZ3i/Dq+UcxGEe669VpxDEfZx8Atzb6+L7JiAtplRtRRiCSEqHMFOpA4iQeO1H+MNFLGhSgU4X2p3I6TNse/xNU4ZBQVnO4zW/1BXc1NwqJCObwjhXfv/MxtJnjs7wwe/vJO2vdMbCkTWyECB+0QlCOEy7Hq2U8kM8mXb+CgYwPnN43slFzevWu2m1MHKMopYe5/FnHHm8GbEVPJ7r/2ef1qWQpK+fn95Uz7P5Nfx9fgvcG2Yt/ik+sHviysmZx99Sjia0kPACT161hnSlMgKZY3I6VnlWBlgaVTGimT52CnDxqOeqygAwhsOGQcTlmdQ+yUeqxyFA46+c12X3DNk5d7qDpGJ0YxacYFzH9zicfjfd6xfH58TVXqbIgQsRiNcH8a1IocwvnS52N98+95lHmRXAZPkb7WSFmxtx6lLYP0Uc5jq3fsxphwTpswqCrkIhRBXMcYHpzVcMVqIHCSgBPPWasQYHUOoFDei0bkESvuxSBWeP0REAIMYguKqEBKBYeMpFA+RBGPtcRLaBbdBnbmrvem0W9ML5L6d6Dfmb24863r6TY4CUt+qddzVJXHhlHw/t7VXs/xBXlpdcvcGmPqV1MMFvqd0dPrdp1By1lXjfL7+HYvC9tSgtRf6pPrB9+UtgZSSuwVDrR6TZ3FKqnJ6ayfv7lKLMoVKyvht69WMeYfwReWkOiQGAH3L5xT6rHTjkgxC42ozhiS0vvrFkIe/78TDUXo5EGsQZwNU5PeI7rz6Jx7PLYnJMWxd90Bz+2d48g8lE1kQgShRrXxeG3C+QQtBz22S6nBKn3/HQgJ997yTR+m57IHJ3jdF2xc/tBFHNuXwdalO3Ecz/DRh+gYYxpB/zH+T9cslVPR8l6VGieAnR6IkKlg8S6B3BSC1rEvfPtX1s7fTGlROVEJEVxyzzivEqCL3ltGYba7k6wos7Hqx/VB5tidRPA6BrEBhVykFFXOWUpQRAXhXpT4hJBey5ZqoxPJx2OGDuoShAp2pj4+iYNbj5C2rzovO6pNJHvXHGDjT9sIiwyl31m9uPFlU1CISwUDgjzCxddV91IlUoIkFKcf+mqOv+lsDmw+QkWthdILbh5LUr8OPh/PHygahRkf30JuWj7r5m9Gp9EzaHwfvze4rqSci5EykjDmISjHLpMo5i7ihG96MQelY1/++SoWvrOsKic2Ly2fL/71He16tKFDL/dHmPI68mbt1uBanQ/nK8LEL24iTVIqgKZqwatuInBILQoFSASK17h7PrHiVhSKcRJNqZxKOeN8+yL8THSbSJ784T4Wvr2UzMPZhEWGsm35bjIOZgFgKSxl9dz1RLeJ5Ip/TgywtcGBkdkowlNsSwgQlBDNTEpkJham+WQ8a1kFRXnFOLyIf237bTdXPnJxq/rRjWsfw8S7zic+Ph5f1tY0BitnYZVn+eXaQfkJrJ23yaPQoSCriJ/eXeZx7LAJA9HqPWeonfoG18zBINa5OXXg+MJoY36ASnESgZ2uOL10PpcStGSiF/vRikz0Yi8R4h20rVCuxxgTzjVPX8b9n9yG0+70iK/bbQ6PUvZTm/rvHyEchIn5uLT6msfGn7fx1AWv8NmjZhy22im4rubRucf812aupchNy+fv9QewFHpft/AtEl98NrUJyhl7Xbmw3larz7jydLYs3cWuVX9TVlSGVq8lqV97bn/1BqwO7yv3gaEOedNGIHCgEy7da2/y5K7ZmfsPoUYUEM4cCuW/T3jcQGO3eb/h65SKPQWxcANhcomXWodqBEUoFOLkxHOzK8oqML+8kMxDdbe604fqWnU3IrvNwfv3fMa+DYcozi0htkMMoy8bxpRHfVvu70ISzueEiD8QWHASR4m8HjiJF0/b9Uzk0PYUt20arcLg8z3VgBVFYfpHN7N/82G2LttFlwEdGXrhQCJiwrHmBI9jt8k+6Njtlltfma4oaLjpbiXe1pBrShLURIv3JgithTOnjGD773s8mhJ3HujbvOzWjJNESuUkwvjJ44mwGi1OPFtINoWdK5Pr7ENcSZcBnQiLbIn+of7B/H8L2LR4R5UwWE5KHstmr6LvGT3pf1Zvn44VyveEi29QROVkNYtIXgP7EPCSNddUgjIUc+2zl9N1UCc0OleIJSTcwMBz+3L21aPrPKfH0C5MeeRihk8cjBKE3ZOKuRMrI3FKlyyoQ8ZSJi+ggkFNvlbNFEhXZar34wSFGPiVGPEAseIuIvkPguavuLcUQ8b154wrTyeqjes9CzEaiE+KozivhJ/eXYa1rPE/iCczxdxPjvyUcudAjyc6l3LgSJo7h9OH6uvtShYaEdIqCpPqY9+Ggx4yxGVFZfz+5V8+HytU/F7DqbvQihyU8lk+uX5QztiNMeE8teAB1s7fzJGdqQwZ15++Z/QkL72A7KO5dOrTvs4KxuBFT6mcjCJy0UgdDmKxMYhyOR4d+9EIT1mEurByGk5nPEJUoOUQOg55PU6hjCjxBopwxQr1Yg86eYBc+S74sWWarxBCcONLJibdO45NS3aw9JOVZB3OIedoLpuX7GD9T1t4dM49rfrx3xdoOUAYZqSIp1yORM9OFCxI9FjlUAp5ttlj9D2jJ4nd25CanO51f3h0mNcw4UmBH7KI63xKl76ZeAXf1PY4Gq2GM688nX88czm9RnTnnTs+5bmL/8tLU9/mqQkzMb+0INAmNgktfxMlXkUv9qMReejFfiLEuwjKKZIzcEpP5+SUBmyyE7LGnWWXSZTI23CQgEO2w1HPI7bAXuXUq+04QAj+bXDsa+I6xJK6J809FCDhyI5UfvzvL4EzLAgIZQEx4iHClCWEit8JERsBHRUMIE++TCEv4wvPpNFquOOt6+k6JImwaM9wS05KHh890PwuQIIywvmaKPE8ofyEPxYW66LXyO4Ixf290uo1jLx0qM/HsnuReZBSh9Sd55PrB61jr8l3//mJTYu3u/LVpatsefnsVWz/Y0+gTWsAKxwX64oQr7m6pNRAIwoJE99h5Tws8tJaIRaw0Y08+V+codMplyOocPbEQSgx4hEilC8wKl+h4xAO6flFk1KL08usXAgHeoL9ffMk46D3Rbu6RMVODeyEie/dnvaEcKARBRjETmLES2jZ57PRkvp14JmFDzL+xrFe96fsSvXIbW8MGv4min8TK24kQUzGKD4iVCwnUrxOrHgAaBkp4KmPTWLYhEHoQ6u/N/YKB3Oen8fu1X/7dKwieR822aPqO++UoVgZiTT4ZqG2VTj2v9cd8Ih9lZdYWfG172NfvkBQRLR4jHgxjXhxA7HiZvR1fMEUytGQSpj41S2zwSUbsIc4MQMcKeg4gl7Zh0HsRSOq9VRc/w7DKvvhkEacMhSb7EyJvB4HnqqITqnH6ifFP38SGuG90KY1L9Y1Fw0ZXntoVu0X2USJ5/FlzzUhRJ0Nxh1OiWxKPMaZQ6y4i3hxOyHiN/TiMIqoqO5NIBzo2EEE7/vA8obR6jRMeewSD0XYnJQ85r60sGmvrQEk0eTKDyiU/8TinEK+fIkC+TwI37jkoIyxN57gLKGPFs9gEDVV2rLqPNYukwjjO4/ZfCVakYGsmOdRWVgThTws8gkqcG+vZZfd0PB61bWlFNgYgJUzGv9igoRL7h3PoW1H3aqMYxKjuPS+CwNoVWBxEo0TIwoldR6j5ShG3qMETwmHE+Wsq0ayfPaf5KW7C7YldonHENr4ykml8Hq0IqXeY4SAMOahYxf58r9I/Nsge/3CLVgKPLPp8jMKKS0q8/F6jpZyLvIiwN18WsWMvfeoHigadyceGhHCudcFn4PSkO5Vt8MbThlOMXfQUI67aGDG5Sod91S4tHIW+fIVyuR5lMtRFMs7yJf/oZV87G50P60zl/9zIj2GdaZj73b0OaMHt795HZ37B1chWksiMVIhh3gViqtECAgRa/FlrFpKPPJro9pEcMtr/2j0NSJ5GiHrd+qVCAF6sY8EMQWND0NL3miTFIdG6/n90Bm0TfrRCjStYsY+5dGLyUnNY++6AxTnlRDXPppRk4cxYGwfwCUrYCksJSYxKuDlzIISj2Ihb0gJFnkxUeJltBxCSsWrRG9jsNEdhWxixDsISnHQhmJ5F07aYacHhfLpE7pusLB5yQ6+f/Vn8o7low/V02VQR+5+dxqGMO9iVKcSRTyMU8ZgYANaDtYh81yKwIJsZi57JZ88PMejuU25paLRcrda9hIqVjX5eVsRFcRxNxZ5LRZubOLZjeP0S05jwdtLSau1dmMpKKW0uNxn7RtromUvYfwACLDfii/a47UKx67Rarjn/RvJzygkJzWPDr0SCYsMxWF38MnDc0heux+rpYKYxEguve9CP7e2qh87XXGQiMJht+1SagE7QlRWj2oIFz+i1NCJqavQyBuVPS0loYCTaPFcjQyYZAxsJE++gp0Bx7dZ0XIYJ/HNqkBsaYrzSvjqme/JSXWVqpcWlbF1aSH/e3gOd7/rG/2T1o2GEu6gRN6Bli3E8ojbPQXgINanIYyMA57Ns60WK/+97gNe/evpBvsghDHvhCcxirBh5AuELDkeXvJtOFar09B5QEdPx15YxtyXFnLLq75t3xjGl4QLM5rjLTBl8VrCuIpSmjdOq3omj0mMoufwrlULZl8/N4+/fthATkoexXklHN2dxlfP/kjusUCK/Wsplrdil9ViZQ7ZlkI5nQo5uMp5C+Hw+AI2peNTqZyMkyi0HMEgdnmkNSqilFjxMFq2E8Z3xItbiRXTiRO3EyWehiZUuwaS5bP/rHLqNTm8PQWnU5UWqIkrN1q65ZM7ZCQW+Q986QArCwdrk59RyC8f/tbg+bKZ6qNCOAgXPxLOp826Tl0UZnrPJc88XLecwokgsBAmFlU5dQAhCwgT3yNoXtV8q3Lstdm7dj9Oh3v8OT+9gF8+/D1AFrmoYAy58iOKnPdQ5LyDHPkh5UxGiHKftOuzyU5o+Ru9SK5XI0QRZUSK9wgXX6AVKSiiAo3IJYQ/ieDd5hvSAlSUeU+fczqcvkz2aPUo5BIjnkYR9lr3mMSKbxUEk+pZ10hes7/B8/VsanYxkxAOQoR/suLCveTpg+8zsLTsR4Nnuq6GHGKamebZqh273YvCHEBZSeBaW1UiiaCUqZRyDZJowOYT7RYpQSEHg9K4XHQtqW7pkeDSeNeLXc22pSU474YxRLXxDCO0694mKKUjAkU4X6AIT0egUIyedT4dS1dPqEXfwAKjlj1oRXqdE5ymOHxvDd19waX3X0hMu1rtG9tGcukM32Zgubqped7bQoCOZIz874Sv7ZMYu8lkmgC8iavDwyyz2fyyL74dBGUAACAASURBVK7bEO17tCV9v3u8LywyhHOvO7Mlhm8UGg4TxjzXwpaXx6umxNWrrika/5gm65QOaB3T3fiOsVx0x7n8OmsFeekF6EP1dOydyC3/bXwGxqlAza5bNRECFFnodd+JUjvNsRJFqzDh9nPrPTeKx+t16hWyH/paYnl1oZCLhsM46NLwwU0gqW8H7np3GvNfX0xxngVjdBiTZlxAtyFJPh3HQXts9EGR6zxerxCgZ/cJf02b7dhNJpMGeBcYD6QCG0wm0wKz2ex3MfAb/3MV+RkFHN2Tht1qRwiBw+Fk4Vu/MmiUpxJkSxPGFxjF1yj1OGIn4UgZhlY0Ln7XlB8BKQUWOQkjP3r0vrRJ/7f/8gVbl+9izY+bsFntRMSGk9S/Iw98dhs6Q8to3QRq0tJUSuVEDKz2qHdwSh1Wxvh0rIg4731NNVpNgxpO2no0key0J5/30Mo9RMh30Itd9d7viigjhqfJlR8gfaCIWJPeI7rzyDe+y/2viwL5b+LFDWjxXJCWzXDPvniWHQHsN5vNB81mcwUwB5jsg+s2SGSckcfmTicy1pWCJKXEaqlg67JdvHpTy1Sr1YWgEKP4ql6n7jrOiTyu+Hii1P34KrAxCou8ArtMBMApI7DK4RQzo1ljtgSF2UV8/uRcjuxMpTivhOI8C7tW7eWrZ35okfFrTFouAvoB15hMpsDPGLxQwWhXllRtdUcM+DLi6nQ6yTrivdrVVm7jo/u/PKEKTSmhVF4JgJ2+5PMO/8/eeYc3cWV9+B1V925jm15ML6GEFggtQEIoIWXSQxICm9579sumbHp205Pd9EbYTBIgQKgJvfeO6QYbjHu3LFnS/f6QbSwk2zKWLNnofZ48waOR7hnN6Mydc885v3LqbpWr5hSBNK2+UfboKRBPVXV9rcQqAigTIy/4U91xxlsC1SsN0iq2NQrbl+whP9Px0fD4npMu59V6ggAc23I6QyUZ0KqON2gxqaZZjYU4zLSmhLvIEV+Qa32LHPEJeeLdijRJ32bpl6vJOT8jRuBU8NpDeG3SUn8krAQ7XAtqqZggfnPbKNsW7SH1wOkaX884nsnpQ847QAKYa6mTMnBdtb8k8sWrWEXttQqSBGrO1LqPr1POAIrFbZSLtggpErNoRamYiqEBl5o7YuzO3IqDm5JleSYwE0BRFGJiGp6ED6Cyqh0yYwAsZgthIWGEx3i2BLkmpFJwtrZjs1SFdF61qTuyZezHUSEFjCM6uH3FlhigfW1vaRQ0Go3L595qrCGd0Yrbrp86cDZpcWi048q1XZ/jvlDU+SanRczBATkEhpwbuyG2HNt6knJjzd65rNTEmp+28PCn9zh9/dQ6HR26O6banjqqp+Wg822KgaJRUL6kxvEEoA8dj17fsO+2Mc5P7TwAYiaSKg+s4QRI+gbJkLvDsacBrav93Qocb6GKonwOfF7xp3CXcGyPUUlEt4x00FqMaxNDuWRqdIHaStRcSoykdkhHFEKHINAhU8Wd2B5rx1FkuBsM3jn+mqiPaPBlNw5g7W+bKM6zz9GPbRdd62ckJiY2yMZquDRpceXabgyx5EgpCr100m6bVejJLxuCqezc2A2xpVWPeNRatVPNUwAErP55Ax36t2bwFPveRUW5JZjLnOewZ6YGoO/oaJPEw0RI2WjZ7VD3YXsdjEWLKSrqUe9jqY6z70QIwcofN7B9yR4kCQZN7sewGwYiuXsWZmdHHNk52UCR09ddvbbdEYrZCiTJstxelmUdcBN4PuhVUlDKRzO/5tVr3qfcWF7VcU6tUZHYOZ4HP57uaRNqxUJLyhhsF2KxChUGMd6jlZ9CqDFxCUU84bExGovW3Voy8tbLiGhhe+rS6jW069WKu9++qbFMcGnS4isUifsxi3NRUCEkQE2Q9LvbwhVDpg6osz9PWYmRP79Z47D9lzcWkJ3ufNH75NEIp9sFQeSJdykRU2sMV2pqEJppKF8/9T9m/WMO+1Yns3dVMt+/8Eujre80lAbP2BVFMcuy/CCwFFvmwNeKong8SfqjGV9xcIN9MURiUgumPnEV/cb1Ij4x3muz9UoKxCuY+Qkd2wGJMjECA1MIEIsJ5fOqPtoXkvIohAoQSJLAIiKwiGgsUitMoj8GJtBEukXUyQ3PTmTMtGHsWLKHyMRIDm0+ygfTbfJhnQa058bnJ9dZwt4AqiYtwGlskxafzbM0k0SO+IwI8TI6aReSZEGilAA2oeYMueIzBM4zWlxFo1Xz1E/3o7yxgLTkM6QeOENZiWP+/JFtKTx66Yu069WaSQ+OpWO/duxbm0zy2kTadSmjdSdbOMZqhcO7A9m+oT/DnEdvACjldkJQnNskpaEWaViciFdcKPkZBexddRCz6VzYyWQoZ8eyfUx9/CqfV3Bzyy9CUZRFwCJ3fJYrnDmawan9jgs4RTnFtO/dxpM/9HqipoTbKRG3220tYwJmkUSQUJCkUvTsBFFaL+duoj9FYjoakYKJvlhp0VRS0+tNVEIEV9x1OZ/c+w1bF+2u6s1/fPcpstNyeeTLWjxCA3DXpOXUgdPMW7SUkOhAht802KNdAgVhSFKxQwhQwymC+I0S7mjwGEFhgdz5hgzAE0NedurYAfLSC8hLL+D4zpNMfGgseWfzsZr1PH5NEjc+mEF8GxNHdgcx98tYnv7f5FrHlChHoHfaYE8tFRAsfqCQ5xp8bJWkHUon76xjuLQgs5CzJ7Lo2NdR68CX8BUPWC8Ks4oodZLxYig2UphdRGwb329yZSaJQl4gQCwiQNpYz/x0FUbRHzNdMdPVc0b6EHlnCzi05TyxYQFHt50gOy2XmFZRHhm3oZOW757/hc3zd1CSXwoS/PndOh7+4m4Sk+LdaKU9KifiG5IEGlLdf/N34fMKsoqY9eK5EEZhroYvXjkXzhlx62A69W9X62fYYuw1l9irpDy3HltiUjzhcWEUZNr3jQmPDaVFO28usrpGk6zJbt+ntVPnHds6ijY93Pc41hgESBtc6nRXGV+0imCMDKKU6z1smW+RczqX4lxHQYnCnGKyU73Z9K1mTuw+xabft9ucOoCA9KMZfP/3Xz02poZDqHEMQQohUSbcX5FtMtZfCu987nqz7jUTCy2xCufxeSHq14rAFaISIug+rLNdwzONTkPvUd0IiWxYOKsxaJIzdn2QnvH3jGD+h8ur7qgRLcK46t7RDrJWvo5VBNfZeE8ABnE5FtEZI/0wU78aGYkiJAxYicXXVKeMpUYW/WcFJ/emEZkQwZRHxhHRwrFveMvOCUQlRpJ1yn42GtMqitbd3JYF41bW/LyZ0gLHArXs1FyEEB7JroiQ/uH06U+gxchgt48XFh1CYZbzDA5XkCRbQze1pvaOj2Y6Y6YtOhybjNlaYbv/KX3m+7fSulsie1ceRJKg3/jeXHGXexuqeYqm5QWrccWdl9NnTA+Wf70GSZIYd88IohMdVYR8nRJuQS+2oJYcW9NWImErYjBQexzS8X0lhEv/RMNRJMqx0IJC8TBmGpYa5i6MpUbeuOFjTuw+1xxt35pkHvt2Bomd7EMVgaEBDL3uUpZ/tYrSwrKqbYOn9PfZhayoBOfCFtoArUecuoo8VDhPoxXokBBuj8Rc+bdRfPXEbAdNYlfRB+vrdOqVmEVHtBx1uHEJAQZGXtD4taFSqbj6vjFcfd8Yt3+2p/EZx16YU8yK79dhKitn9O2XuRQzjW0dzS3/mNoI1nkOC20xiBGESPNq3EegIkBajlVEYMS5QrwzwqXXCZA2Vv2tJp8I3iRbfAl4X31o8X9X2Dl1gMyUbJTXFvDoNzMc9r/2iavoOqQTK79fhxAw8tYhVSpavsiYacNZ+/NmMlLOhUbUGhU9h9ddKn8hCNQVPVOctbFQe6TaeOjUAaz/ZSsHNx6pd4xbpVZx84vXuLSvhmQCpFU1rkXZnkb9VOITjn3b4t389PLcqvLxdb9sYcK9o+vsFOfLSBQRwudopZNYCaRU3IiJfk73NTKSILGkxhYEElb00l40nKJQ4JJzlyhF4+SxVU0aAaygjKvqd0AeIGVvmtPteRk1F291H5pE96FJnjLJrQSFBXLvJ9OY/fJc8tIL0OjV9BjWxWVnVl8EYZhpj9rJ4qltepCJlTi3jqnWqHnyx3v5/oVfWfPzJpdn7mq9mndXvkxUG9f6JAUxv8bFU0mCcF4jV1x4m1tnmAwm5vxrMcd3nUSj0zDi5iEMmtTXrWN4Cq87dqvFytx3F9v1BCnILGT5N2sYfuMgN6uCNxZGoqQn0EqHq7ZoOUSheAQjlTcrMypysBJRIXGnxWkPgmqopQKC+A2jcObYjbb+NBRTxmWE8J3TRTRJEqhEzar2jUlUgvOilKBQ3+9j4yod+rThhTmPEB4WQV5+rsc1eQvEE8RyO5JkX/avlgoJFEsp4fYa3nnhaHQa7nr7RnLO5HFg3WGbCEotRCZGMP3tm+jcr73LtSaijidMDSfRcBwzHVy2u9bxhOBfd/zXTjjkxK6T5JzOY8K9o90yhifxumM/eyKLnHTHVp7ZqbkcWHeIS69uGnfI6gSxAM15aupqKZ9gfsMoRhHErwRKC1GRhyAYiWLUkmsLUCocvysNB4iQ3kBNGpIkCBH/dVp+DWAWcRgYW/+D8gCTHxnP3tXJZFYLVYTFhjLhPt//4dQXrU7TKELrVqKxEIfmvEpTISQseCYlFECSJB7/biarZm1g7+pk9IE6ju44Qe6ZAqwWK7ogLcHhwfQb25OrH7yi3uthpcgEiGWopRLn41dMlHCTY9+7+iBHth63t6GwjPW/buHKmSMb5Vw2BK879uDwQPSBOgyF9nFBXZCO8Dj3qKo3Nlop2aEvNoCKArTsJET6rlp/9IJ6pWqpSUciC1EVUxSESR+ikc71qqrNqZeISkUn7xMRF8bj383k59cWkJ+RT1BoIFfdO5peI7t527QmjI5yuqIWZ+zi0RZaU8YVHh1ZrVEzZtpwxkyzZY4IITiy9TjHd52k65Ak2vVqXccn1IyFBErFVYTwq9M4u4UWlLsxKWDOO4uxmB2fPErySzGWmAgMbUiLLs/jdcceHhtG256tyD8vrtqqczxJA7zfjfBCMIleBLDSofrPSjAh0o8Oohf1SZBQSSZiuItScR0l3FWhIuPYpP98rCKIPPEWFh/o8FidhI4tePRr55WjGSlZLP1iFRazlXHTL6dl5wSn+/mxp0A8AxJoxcFq2VCP0NgL5pIk0XlgRzoP7OiWz1NhqPG3UiYGu01sw2gwkXfWuSCIVq9FH+y5ymF34XXHDnD/p9P4+qnZnNh9inKThcROccz84HaPdlHzJAYmEMhSm7RVBUJQkXbY8IQzW4/tuRjFMCzEu6T6biEeC+6V9vIkK3/cwNx/L66qU9i+ZA9XzRzF1Q94dtbZPNBTIF4EjEiYEDRMyMVX0JzXubISmw5wKba0nIb7jMLsIspNzlsTt+vT2ufDMOAjlacBwXo69muHWqvGWGIkIyWb397+A6u17opM30RLnngXk7VLRYe9Cu1Jyewwi4eaq+ZqC9GopUKCmFfxo619JmYR4ZSKKeDCDcAXKDeaWfLFSrty7qKcYlbO2uBV8ZSmh77ZOHUbzv2BJEGAtJpA3NN5MSohokqVrToqtcTkh8a5ZQxP4xOO/diOFOZ/sIz0o5mUFhrITs1lw29bmffvmhvsw7kY3rz3lrBvdfIFSXJ5CoEalVTiNNYO9i0CLEQ7deJ1PbAIbI+E5hq62llFCAYxkjzxRoPUWBqbtEPp5J52LNjKOpXDke2eadHqx/epLVddJZkIkNa6ZRy1Rk1IpGNYx2oR7Fi2zy1jeBqfCMUs+2o1xXn2q93mcgv7Vidz7ZMTnL7HYrbw4T1fcWjzUQxFRvRBOtr3acPj3//No93zXEVFAVINzfLB5rRLraMo5XrMJBEuvYlW7EdNlku9YywihhJurPh3gtMnUAsRFIiXLvQQGpXcM/lsWbiTyPgIOvRtQ2BYAKYy+0XgoLDAJlldXJ3Mk9ks+s8KyorLGH7jYHoM85youK2W4mt00m4AisS9mBjosfE8Tam4Bj1batQRlqhB/OMCEDWEdM7PlPFVfMKxm8udx7Nqy4dd/vVq9qw8UCWLZyw1kbzxKL+8uZDbXr7WI3bWBytRWIlCXVOJt1BTTq+q8v4C8SISOURLM9BQe1MriwijSMzEiq3svoQ7CBSLUEn2kmMqilGRi9WDaW7uYM6/FrP6pw3kZxSi1qpJ6BhHQlILCjLtb4xte7akZWfPdUX0NJsX7LQVK1W0g925bB9Dr7uUaa/f4PaxJEqJku5FK51rbx3JMxjESOAjt4/neQTBzKpq23u+hoEQEkbRx22jVQr3nE9AsPcrtl3BJ0Ixl10/EH2Q4yy7XZ+aF/v2rTnkVOs0ZU+qk729gYZSMQWLOKe5Wj3cIkkWQqQfUVeT1BRE1ZmKaBYJZIuvKeNcrM9WSu7YcU4t5RPAXw04Bs9z9ngmK79fR36GLZ5uKbeQlpwOVhh2w0ASk1qQmNSCQVP68chXjm0GmgpWq5WFHy236/FdVmJk6x+7yEjJcvt44byKBnvNAkkSBEproNzjOjhuJ5iv0Uvbqp5mz3fqJvpSwp1uG2/MHcMciiPDY0O5+v6m0TfGJ2bsfcf25LLrB7J9yR4KMgsJDAukQ5/W3FJL6bVW7/yOqtH5zgKhgWsoF50I5lf0bHZ4hFRLuQSLnynkyYotEgYxATWfO8y+wXZjKCcJ4SCtp3NamSeECiu+XQuw5n+bKMxxrITNSs3h6dn3u9wgytfJzyggP6vQYXtRTjE7l+1zc/sMEzppp9M1GkmyoC56gDAGUcRMhI9fH5UESQtrXHOSJIHFmoA73dmACX0oyi1h1az1FOeXEh4byoR7x9C+lsmmL+ETjl2SJKa9fgOTHhzLwY1HaNk5vs5ihnHTR3B4yzE7oeOAYD2XXXepp82tF2Z6UiB6Ei3dhcqpNqN9/4tSrkcv1qOXdjrsKUmgF1vQsp1yBlRtFwRSThIazp43dmvKPND1zp2ERjnvba3RaZBUTTPd1RnBEcEEBOkpPG/dRVJJGA2ON/GGYNMArVmUQiKbINUfaMUhcsTHgG8X29iofd1JJRW6XURk1G1DGXXbUI+1WPYkPuHYK4lKjHDZMXcbmsR1T1/Niu/XU5RbTFBYEEOm9me4PMjDVl4YZjqiPc+xW0UIpUxBx3qCpZ9RUYiVcMpFD3Rir0O/DwCVVEYQSykQA+y2FwqbLJiWw0iYK4pSHgO8v5BcE6cOnCZ50zG0eg3lRvtjTerfvknkC7uKPlBH92GdyTmda1fRKKyCRf9ZgbAIrnn8SreMZSUS0AK13zA0HCOIeZTSaOLgF4xJ9CRQWu/0NSE0HhERAVtr6XKjuUmIa1THpxx7fRl9+zBG3jqU0gIDQWGBqNS+6wgKxaOoyETLUVRSKRYRg0FcgZp0wqW37doAaDhFOe2cigoAWJyICgiCKBCvIlEKmHymbUBNHN12go/v+5a8an2CVGoVkQnhJA1oz51v3uhF6zzDtNdvQAgra2ZvsltvKSsqY8OcrVx17yj0QQ1fnLMSh5mW6Jw+IZ5DkgRa6t9u1xsU8Th6sR2JsgphjQqRDhGAif6Uubn/kbHUyBePzeLE7lTM5WZiWkVxx2s30LZn01BoazKOXQjB0i9WsX3JHixmKx36tkV+bhK6AG2TuJsKQsgTH6DhIBqRhon+qEklSnoK6bzeLmopj3LRHpO1J1ppn11s0SziKUWuZZwgcFNptSeZ+94SO6cOtiyoAVf25paXvJ/V5AmMpSYOrDvitGYhr0Ikua2bpB1zxQfEcgtqqeZOnkKoMAnfEF2pDQkDkdLzdm2tbc5dwih6UcA/cbcy2OePzmLbot1Vf+dnFPLZg9/zypKnasyY8SUa5NhlWX4HmITtme8YcJeiKM6bLDSQn16ey8of1lc9sh/bkcKZI2d5+qf7q/YRQrB3dTLHdqQwdOJA4pKifCw2JmGme5W0XYT0soNTr0TLcbKYS4j4L8HqrVgsRViJrUhz9O30RVdwpl8KkHXKN/VL3cGCj5c5SPtVEhoZ7OYc/TByxBdE8gxa6ZTTPcrphIGJbhzTMwTxGxoOOWyXJEEA2zCIbZhw39qa0WAiZa9jdl3GiUy2LNzJsOt9vxagobGL5UBPRVF6A4eB5xpukiNGg4ndf+53iMMe33WK47ts/SOMpUbeuP4jPprxFfP+vYSXrnmH9+/6AovZfUUL7kZFzXJ4thmIRDH3YgmfR7aYRa74hHLcl6vrTUKclGwDxHdsvko4acnpNb7W/bLObn/ytJJAibgVIRx/5hYRTJ54E9sajG/HYrTSoVozYkKlT906ntloxuykV4zVIihyksHlizTIsSuKskxRlMpvYBPUUNveQAoyCylxIgpsKDRwcr8tV/eXNxdyaPMxTAbbDLi00MCeVQdZ/rV7yow9gRXnzg3ATNtzf0gStsWw5sPUx68kLNb++Ft2iWfig77RK94ThMeGOd0e1zaGu9/1zAJmGSNraDmhIYg5REn3EiPdTJQ0g0B+94gNDcUs6hIrd+/kLTgiyKk0Z2R8OEOmDnDyDt/DnauNdwOL3fh5VUQlRBAW4+gEQ6OD6TakE4DTRyer2cq+tcmeMMktlIqJWIXjLM0iwikRvp+pcKEIIVj3yxbMporsEAlCooJ58L93N1HFLNe45vEriW1t7zDC40K5+92bPJgBpCdfvEi56FjVkA5salwh0ix0UjIa6Sw66Qih0hfoWe0hOy4cI32wCudTdiHAINzf8fOm/5tCaPQ5nxPRIoxx00cQEef85uxr1Bljl2X5T8BZHfcLiqL8XrHPC4AZmFXL58wEZgIoikJMTEy9DJ1wz1h+fnMuRRU9ZbR6LZeO70vPgbZ4dWCwczm1kLDgeo/VeExDGOOwGr5Fsp4EJIS6IwRMJ0x/rmBFo9H48DHUD41GQ9qeDDbN24GhuGIxTEBxbgkLP/yT5396xLsGepDoxEge+WYGv76xkPysQoLDA5lw3xi6DfGshquFTphpiVY6Zrf9/AZ1KqmYIOZjFCM8ak99COETgqQFqGpqpoeGUm5265h5Z/P59hmlKuwiqSSiW0ZyxV2uC8l7mzodu6Iotd4OZVmeBkwExiiKUmOwTlGUz4HPK/4UrmodVjL81kuJaR/Bn9+updxk5tIJfRh2w8AqzcSBky/h8NZjlJWcK8wIiQpm1B1DXdZV9A6XVvxXgRUoB4rO2RwTE+Pjx+A6MTEx/PHlsnNOvRop+0+55TgTE+t6dPcerbsm8th3Mxt9XBWuxYalOnR3GxMVmQRKK2oUeQcopyfuDlPOfuV30g6dWw8RVsGxnSdZ9tVqJjYRPYCGZsVcCTwDjFAUpbSu/RtKt6FJdKtBoX64PIiME1lsnLed8rJyouIjGXHrELoMco96ix/3ERjivNJRo2sy2bdNDrNoh17aUfeOwr1VsA1BxxbUkvMsokoswv1N4TJPOZlciKbT2REaHmP/GAgFlsuyvEuW5f+4waYL4pc3F7Jx3nay03IRVkFCxxYMv9E3q1AvdgZMvATdea2VNVo1PYd38ZJFzZ9i7sIkkurU19VKRwjnRWyPjd7ESACrarXXKvSUcJvbRw5w0pAQaBL1MpU0aIqkKEondxnSEPauTuav79ZgKLKFYQpzitk4fxthLUK4+f9qbiTmp/FZ8Nkyfnp9DqaK/iiSJBEcEcjASX25/lnfz6luqghCyRMfEsLnBElzayznkSQIYA3wOgXiH41poh3h0lvo2VZjmqMQEgXiCSweSMQbfccwUg+esetDFZUYweRHmoZ6EjShytPaWP3ThiqnXomwCg5vPlbDO/x4A5PBxIJPl1KYda4RlhCCgJAA5OcnN6veML6IIJAiZhLE3Fr3kyTQiv1IFHlFWk/CgJaDtSqImeiLEc842oET+2I0mFj5wwZKC0oJjwvj2ieuokW7plNj0Swce434VNWpn9TkdKfxy+zUXI7vOkmPYf5QjKdRk41tsbH2UIuKUlQUYPGKZmoZUg0CNWDrD1Mi3JsJA7ZJxqFNxzi0+ShdBnXi/35/1Mcq112nWTj2kbcOZd+aQ3ZCx5JK8i+c+gj5mYV89/wvnD6cjsWJKlZwRNOXvGsqWAkDKRrE2Vr3E4CFxk+xlcgnkmdRUXMuhoVYt7YQACg3mXn31v9wdPsJykqMBATr6dS/PY99O6NJLuo3i2ffnpd35Yq7Lie2TRQqtYrwuDAumzqQ65/xx2y9jcVs4d93/IcdS/aQcTwLq9nRsbfr1Yb4DnFesO7iQxCO0PSxK1YCHBYpVRQTI91GhPQsOjY0im06thMtzUSnqrmFANga6rmbn9+cx761yVXp0mUlRvatTWb+h8vcPlZj0PRuRU4QQhAeE0pkfAQBwQF0HtiBhz6aQUGhrR/Zqp82svbnzZSVGIlOjOCWl6b6HUkjsWXhLtIOOc4O1Vo1cW2jad+7DdPeqLlbpR/3Yw15A1OOBi37kbAgAK1kX7ktSaAhGw3Z6NiNSXTByGgMjAcnal0Nx9bzRSNl1rmnhQS3j75/wyHHljkCDm9pOimO1WkWjn32K/NY+cP6KlX71OQzFGWV8MDnd7Lix/X88vp8SgttYZq05DNkpGTz4vzHCI5ovuXrvsKZoxlYyh17eYTFhPCPBU8QGNoU1HuaGZKOQp6qcmShvO/g2KujkgwESLvQi10EMYd88SoWalc4qx/lhPNPNNSe7CCErYdSkbjPjWPb0Opqktpsmi6yyYdijKVGdi7bV+XUARBwYMNhUg+eZp2yucqpV3L2eCZLPl/ZyJZenFw6oY/TG2hEXDgBIU1D8b25Y2ASQtTtwCQJtFIKYdL7bh0/XHqNAGl17eEXYYut54pPseL+7JSr7hlNULh9W5KgsEBG3+4ZZSZP0+Qde97ZAorzSxy2F+eXNGwnVAAAIABJREFUkLI3zW5BtToZJ5tHib6v06Z7S/qN64W+WtFHVGIEU5+4sslmHDQ3zHRE4LzXkjPU1L7w6jKilHDp7wSwps4ENjNRZIsfEXimSGjI5AFMfngcrbokENEijFZdEpj8yDj6je/lkfE8TdN8zqhGVGIkYTGhlJ7X1jc8NozOl3Zg49xtnDmSYfeaWqum96hujWnmRc30f93MwMl9Wf/rVmIToxl952VEJfq2dN/FhoVoVOcJbdeEcJOOrqr4SQKldXXuZxUB5Irv8Exs/xwjbxla9XQ5aFI/u8lIU6PJO3ZdgJbLrruURZ/9VTU71+jU9L2iFy3ax3LT36fw4cyvyTpp6zmh1qjoMrgjQ67p702zLyokSaL3yG70HtmtWTU0a06YRG80nHTo+Hg+QqiQMBHGa5RwExbql1IsUYqW/QjMSOW1964RAqxEkSve83ih1Iqf1vH9SwpZp3JQqVUs+s8KZvz7Vjr2bVv3m30QSdTVPMIziDNnzrj1A3f/tZ+VP27AYrbQb3wvrnt4Erm5Npm1gqxC/vj0L3LP5NNrRFeGyQNRa9RuHd+TNCdn2BjHUtHdsUFxngbIPjq9tn3pHDq3xUwYbxEgrUEl2VdxW4Vt5ipRDoiqsIlFRFIkZqDmBDqSMXA1ZYxHohgNx1CRQ5C0CBX5WAlGEgY0Uuq5DpKS85MkhISFWArFY5gYjLv1TM+nrMTIS1e9S/px+4ycdr1a89KiJxo1ZFjXdeLqtd3kZ+yV9BnTgz5jzgnzVi9PD48N45Z/TPWGWX6ckHMmjz8++ZOinGL6X9WbgZP6+mI7geXAc4qimGVZfgub7OMzXrbJg2go5AWKxP2E8Q5aUgALFhJRkeNUN1Ut5RHO24BtYVUn9hLG+0A5UoWqkZ1PdME/WkUAeeKflNN4SkW7VxxwcOoA2Wm5ZJ3KIa5t09NCaDaO3Y9vIoQgP6OQgGA9gaEB7F59gH/d/Sk5p216rzuW7WPLgp089MV0n1pMVRSlemXKJuB6b9nSmAgiKRCvY9PNsRLIklqzYKqfMkkCRNkFd/IQQsIoBjeqUwcICNGj1WkoP0/ntKykzGlBXVPA79j9eIxDW44x++W55JzOQ6vX0r5PG4qyS6qcOoDZZGbfmkMcWH+EHsM6e9HaWrkb+LmmF11RB/MlFaz62CKVnEEyuu7cGnJvliRBgDoFbXgoSI2XCjty6mX89uYiTu63z+U3myzMeWcxL/76RKPZ4q7rxO/Y/XgEQ3EZXz3+Exkp5+KFOafznGYaGEtNbP1jV6M7dnfJPrqiDlZX7NRYamTXn/vRBWjpNao7Gq3n1oDqE+/X0ZcIaV6tKkZuxZJGQc4myulR975uZIQ8mO//4VikdXTnCdJOniYguHFuNC7G2Ouk2Tn2vLMFzHl3EcU5pYS3COHaJycQFuONDnUXN2t+3mzn1CtxVoUqqSRadXF/mXhduEv2saFsXrCTX99aSObJbFRqFQkd4pjx/m207+3O6s4Lw8RATFyCXmxFkmznTgjbTafyb3diJRgrjd8QLjDEeR6/xWzBbDJDIzl2d9GsHHtWag7v3PIZGSeyqrYlbzrKc788RHhs01AXby6UOikaA9AF6lBpzJgM5yqFW3aO5/KbBjeWaS7RWLKPRoOJ397+g8yKm6DVbOX04bN8++zPvPRH42ZkOEciX7xGIIvRswmrCKOEWwiTPkLPZpc/RQgQ6O0ybgSO66lmOmGhcTRrzeUWNszZSvLGo3QbkERUQgS56faJT7FtopuUclIlzcqx//rWQjunDpB+NJPf3v6Du99xf/9mPzVz+U2DWTlrIwWZhXbbO17Sjh4jOrNl4S5MBhNxbWO4/dXr0AW4V5DYDXyMrSJmuSzLAJsURbnX3YPsWXGAjJQsh+3ZqblknsyhRTtfiMurMTARgzjXLbVAPEU0d6KWXBPJBjX54hUCWYyGUwi0qAOGYio7hhZbo61ykigUT3rAfkfKSoy8c8unnNh9CovZyqa524mIDycqMYLcM/motWriO8Ry11s3Noo97qZZOfa8dOfN+bPTchvZEj/RLaMYN/1y/vp2Hbnpth9KQsc4HvrsHvThGq7622hvm1grjSX7qA/So9aoHUJUao0Krd53f55WYigUjxHBG0iSfTaJEJJDoZOFGMrphkmc0yGOCY6hwJDNubaKjfd0Mu+9JRzdnnLOPouVnNN5jLhlMB37tiM4IphLrujh0bUOT+K7V84FEBrt/JHJH4bxDhMfGMtweRDbFu8mPDacvmN70CK+hc8U6vgCPYZ3JqFjHGnJ6XbbEzq1ICohgsNbj7Nq1gYCQwOYcO9ooltGeclSR4yMoow16MRW1FIpQqgx0w6zaI+eNagkm66tVegxiqEIavodNn646eTeNKfbM45nc/fbTf/pvlk59qlPTODE7lS7dLrYNtFMffIqL1rVvLBarcx7bwn7ViVjMVtp27MVt748FX2Q88Wl8NgwxtwxvJGtbDqoNWr+9uHtfPP0/8g6lYtKoyKxUwvu/3QaP774G+t+3YKhojvp9iV7ufWlqVx69SVetroSFQXiJbTsIUCspZwOlDEW0BAoeleIYkuUiVEY8K3foFrr/GbSlPvDVMctjl2W5SeBd4BYRVG8Nh1r1SWBR7+dyZx3FlFWZCQoIoDrn7mauDa+EKdsHnz33C+sU7ZgLrc9fqfsTSUjJYtnlQd9YKGvadKme0teXPA4uWfyUGs1RMSFkXkqmzU/b8JYYqraLy89n/kfLmPAhD4+9F1LlNOHcvrYbTUwGYOY7CWbasdUVk7GiRynr4XFuF+dyRs0uI5bluXWwFjAsebYC8S3iyE0KhhDoYGzxzNZ+PGfGEuNdb/RT52UlRjZv/ZQlVOvJGVvKsd2nPSSVc0DSZKIbhlFRJwtXPGfh36wc+qV5GcUkJ9R6LDdj+usnr2RrFTnjn3LH7tZNatxpAA9iTtm7O8BTwO/u+GzGsyn93/HzuX7qv4+fegsBVmFPDXrfpfev+yr1WyYuw1jsZHIxAhufvEaWndtnPQrX6cwu4jSQoPD9rJiI6cPp9Opf7vGN6oZUpRbTOYJx0wZAI1e4yAI4ad+pCWnI6zOyxKMJUY2zN3GyFuHNrJV7qVBjl2W5cnAaUVRdlekhNW2b51l1w0lKzWHE3scq8dO7j2NMd9My07OigzP8fvHS5jz7qKq9r9njmbw6d++5V9rXiYs2ntFTr5Sjh4RHkFUQiQl+fZp3RFxYQybNNglG33lWHyZzJM5GIqdP2W27BSPPrB5xIG9Rb/xPdk4ZxtGg+MTEdjaXDR16nTstZVdA88D41wZyJWy64Zy/GAKxXmOhTFFucUc238cfUTth/vnj6sdFJfOHMvgx9d/QX7Oe/FCX2r5Ouq2Icz912KKcm3fsy5IxyVje6IOkVyysRHb9jZZ4jvEEtEijOxU+zRdfZCOu9+5yUtWNR96j+pO18uS2LvyAFaL48y9VZemff2AC469prJrWZZ7Ae2Bytl6K2CHLMsDFUVxk3ZW/WjVLZHoVpFkHLd/jI1tG0373m3qfH+Zk5gmQHaaLcvmwLpDrPxxAwIYdetQegzv0mCbmxpjpg2nQ9+2LP18FeUmM0OvG0C/cY7yYcZSI79/sJSTe9MIDA1k4kNjadezlRcsbnoEhwfR/8rerJq1AWOp7ZrUBmgZMnUAUYmNX27f3JAkiUe/uod1v27h17cWUpxbisVsQavX0KZHK25+8Rpvm9hg3Ca0IctyCjDAxawYtwttVLLsq9Us+Gg5hdk2ma+QqGCu+tsoJj4wts73vnPrZ+xbnWy3TaPTMOO9WzhzJINlX6+uSj0LDA1gzLTh3PDsRGcf5VZ8acbuCmaTmdev/4hjO1KqtkW0COPud25mjHw52dnZnD2eyeL/rsBssjD6jmFuVapxh9BGA3Cb0MbGudvYMGcbQggGTurLcHmQW7JhfOV68gU7hBAc3nKco5tPEt85hr7jenpVG8AvtFED46aPoMfwzqz+cTOGUgNj776cNt1buvTeW/5xDR9M/6qqLYFGp6H7ZUn0vLwrv771R5VTBzAUlbHp9+1MuHd0lU7ixcSpA6c5vvMkSQM70DLJPlK35udNnNhjnySVn1HIwo+XM0a+nNWzN/Lb239QkGW7+e5ctpfRdwzj+mc8f5NsSgyZOoAhUx17kxfmFJNxIouEjnFNso+JLyFJEl0GdeSyqwd5/SbjTtzm2BVFaeeuz2ooLTsn8PCn99T7RLXsnMCL8x9jyecryUrNoe/Yngyc2JdjO0+ScybPYf/stFxSk8/QdXCjVJ97HSEEFrOVj2Z8xZGtJygpKCUkMpjulyVx3yfTUKltM53DW447FSgozCnGXG5myecrq5w6QEmBgfW/bmXcPSMJi24eecSeQAjBN0//j72rk8nPLCSyRRiXXNGT2/95vQ/ltfvxBZrdjF0IwcofN7BvZTLlZjPD5YEMnNjX5feHRAY7zByjW0YSGhXi0NAqLDqU2NZRmAwm9q09jD5QS7ehSVUOrrmwVtnMX9+upTC3GLPJYvc9FOeVsH3JHpZ/vYbxM0YCNq3ITb/vcEgpC4kI4syxDPLOOvb0yU3P5+D6wwya3M+jx9KUWfb1atb/thWzydZXJud0Pmt+3ky7Xq19rjumH+/S7Bz7l0/8xKZ5O6pSlg5tPkrK3tQGZbVEJUTQ+dIObFu8u8pZSSqJpAHtObEnFeWNBWSmZKNWq4jvGMffPrqDNt2a/so6wP61h/jfP3+nONd5G14Ai9nKnpUHqxz76NsvY8OcrZzcd7pqn9DoEMZNH0FEbBiBoQEO2UcBIfomqS3ZmOxctq/KqVdSXlbOlgU7/Y7djx3NamqZcyaPvasO2uWhGktMbF24G0NxwxRg7v34DsbPGEmHS9rQ4ZI2jJs+gun/vgXl9QVkHM9CWAXmcgtpyel889Rs3LUo7W2WfrmqVqdeiUpz7lLSBep4evYDjLh5MEkDO9BrZDfu/egOBk3uR1h0KEkD2iOp7EMHbXu0op0PCEv4NDVcUs3jSvPjTprVjD1lTyoFmUUO23PT8/hg+peERYcyfsbIC8rA0GjV3Px/9mlQW//Y5bSXduapHLJTc4ltE13vcXwNYzVBjJoIDA1g5C1D7LaFRAbX2AN/5vu3ERIZbIvFW6207prItDdkf5y4Di65ojuHtx63a/ErqSRK8ks4sOEI3YcmedE6P75Es3LsrbslEhodQlGOffN/s8nCwfVHANi/7hDXPHYlY++6vMHjafVa1BoVlnL7hUKVSoW6ifZxPp92vVqRvOGIw/ag8EAkSSIsOoQhU/vT/8reLn+mRqfhjtducKeZFwXj7hlJanI6+9ccIu9sAZIkIayCE7tT+XD6l4y4eUizyMF2N+nHM1n6xUoAxt8zkoSOLbxskedpVo49rm0MXQd3ZPvSvU6zMgCKc0tY8cN6Rt12WYOb6Pcc0ZX49nGcPmxfj5XQKY6ohIgGfbavcO0TV3Fsewon9pzCbLKg0alp37sNj3x1D4biMiLjI3xaEKI5oVKpmPHvW8lOzeH16z+ya09tKCpj84IdTLhvtF9/oBq2upZlFGbbJnvbF+9h4oNjGX/PSO8a5mGa3S/y/k/vZP6HyziyJYXsMzmcPZbpsE9BZiG5Z/LqvViXm57P6tkb0QfpGHHTEIIjgpjx/m18+8y5XtoJneK47+M73HU4XkcfpOf53x5m84KdHNp8jK6DOzJwYl9UahWh/tREr1BWaqKkwFGGNS+9gORNxxg0yfUssOaMsdTIn9+urXLqAIXZxfz17VpG3jKkRg2B5kCzc+wqtYprHruSmJgYNi/fxju3fIqhyL6hUlBYIGEx9Wvqteyr1fzx6Z9VLVNXfLee21+7jj6je/DSoifJOJGFVq/xKYUbd6FSqxhyTX+GXNPf26b4wdZ0LSgsiLLi86/rAOI7xnrJKt/j5P7TTtvzZp3K4eS+NDoP7OgFqxqHZpUVcz4dLmlLu/N6xGh0anqN7EpAsOt365KCUpZ+ucquD3ZWag6/vrkQq9WKJEnEd4hrlk7dj+8REhlMl0EdUKntF5vb9W5D2+7+fjyVRMSFOf2dB0UEER4X7gWLGo9mN2OvjiRJPPbtTGa/Mo+UPadQqdX0Gd2NSQ+71JCyir2rkx067QFkn84jMyWb+A5x7jLZYxRmF6EL1NXrhubHd5nx3q2Ex4WRvOEopUUGrGYLKo2a1bM3MvzGQV7td+IrrPhhnVP9gHa9WtOiXfOumWjWjh1AH6jjzjdq7xVfF+GxYWgDNJSX2fdp1gXoCAoLpKzEyOyX53JyfxpqjZo+Y3ow6aGxXk3fK8otpiCriOK8Yn7+5wJyzuSh1Wlof0kbZrx3q7+ndxNHrbGl3y77ajXz3ltCSX4p2Wl5JG84zP51h7n/k2neNtGrHN2RwtIvVzsk+avUKqY8Ot47RjUizd6xu4MugzrQsnMCKeeJeLTt2ZLQ6BDeuOFjDm06WrU9ZV8ahVlF3PbqdY1tKuVGM58/8gNHt5+gtKiMcqPZLu85Oy0XlVp10f/wmwMWs4VVszbYCZ+YTRb2rznE6cPptOyc4EXrvMvv7y91mhlntVhJ3nCEzpd28IJVjYf/ec0FVCoVj3w5nR6XdyGmVRRxbaIZMKEP930yjcNbjpNyXidDs9HMnpUHMNWg0OJJZr00hy1/7CI3vYCyYqOdU6/kxK5TmJ1s99O0yM8osMv4qKQ4r4QD6x1rDy4mystqKKyToO1FoAvgn7G7SFRiJE//dD9mkxlJJaHW2HLgTx04XSWGUJ3SwjKK8kqIbuSQx9FtJ+qsMTeXm7GYLQ3O4/fjXUKjQwmKCKQo1965B4QE0K7Xxd2eoWWXeA46KawLiw6h16huXrCocfHP2OuJRqepcupgK1IKjXLsiR0eF1qlON+YWC3OC7OqE9cm5oJi7PkZBXz77M/8647/MuulOU5lCP00HroALf3G9UIXqLXb3uGSNlXC4sV5JSz7ajUrvl/n0HitOXPtkxNo28t+Zh4cEcSL8x+/KBaWL8oZe1ZqDvP+vYSCrCISk1ow5dHxBIdfmFhGQoc4eo/pzpb5uyg32h7/dIG2VgNz/72YCfeOISis8VTlW3VLdKiElSQQAtQaW/fJO9+q/2Jy5qls3r31P1UiJHtW2Do/PvfLQ4RG+QuVvMWNL0wmKiGcbYv3YCm30L5PG+TnJiFJEhvmbOW3txeRnWbL6Fr835Xc9uq1jJFHeNlqzxMcHsTf5zzCX9+v4/juU7Tr1Zor7hx+0SQNuE0ar554TBqvkpokplKTz/DBXV+QVS19sU33ljz/28MEhgZc0FhCCDYv2MnG37ZxeNtxSgvOpVi17BLP07MfaNDsvT4SYqWFBt6/+wtO7U/DUGQkqmUkA67qQ0zrKCJiw+h/Ve8LCsF8cv+3bJm/02H7mGnD6tX3pRHFrJu8NF5DMBlM/H3c21U34kpadkngsx1vk5fnmL7b2PiCNF4lvmKLXxrvAvn1zYV2Th1scfKFnyznhmcnXdBnSpLE4Mn9OL7zJLv+2m/32ulDZ1Fen8/M92+7YJvrQ1BYIM//+jApe1PJOpVN1yFJbplR56XnO92ekeL9H4MfRw5vPUHmScdzk52aw8n9qYQlNm1JvaLcYg6sP0JMq0g6XNLW3xn0PC46x15dkq06pw+ddbq9PpwfAqkk66RjWbOnadertUsLaBazBatF1NnIKzjCuSMIj61fawY/jUNweCC6AK3Dwr4uQMfWxbvYtXofGq2K0XcMo9eIprWY+Pv7S1g1exO5p/MICNbTunsij349w6//Wo2LzrEHhTuPd0e3ang7gJpErTV6DaaycnQBWqevewOjwcTXT83m+M5TWCwW4trGcPfbNzltjHZi9yki4kIJiQy2WzCNbRPN1Ceuakyz/bhIu96tSUyK58Ru+1RcSQWzX5tDeYUYTfLGo0x8YCxXP3CFN8ysN6kHT7Ps6zVV4i9lJUaObD3BN8/8zEOf3+1l63yHBjt2WZYfAh4EzMAfiqI83WCrPMiUh8dx+lC6Xd+X+A5xTHmkfm0GnHHNo+M5vOW4XdhCpVZxcm8qL1zxJj2GdeaO12+oWpUXQpC88Sj71x6iU/929B7dvd4r9jmnczGXW4lrG12vx9HPH/mRbYt2n/uctDw+nPEVLy96sirrx2q18tkD37NvdTKlhQbUGhWBYYHEt48hMj6CG56dSGzrpi8m0hyRJImHvribLx6bRcbxLFBJxLSK4vSh9CqnDra03LW/bGHcPSObRPvlP79d51TR6/ShdC9Y47s06EzKsjwKmAL0VhTFKMuyzzdN6TK4Ew/+5y4WfLSckoJSohIjkZ+fVO9uj85ITIrngc+mMfdfi8lNLyDrVDZmk4WSAgMlBQZyT+cRFBaI/PxkzOUWPrj7Cw5vOU5ZiRFtgJb2vVvzxA/3utTPJTc9n88e+I70Y5lYLVZi20Qz/Z2baNOj7uILQ1EZx8+byQGcOZLB7hUH6DeuFwAb52xnx9K9VVKDFrMVQ6GBxKT4Rlsz8HPhRCdG8uzPD2IoKkNSSWyev4Ovn/qfw36F2UXkpuc3if4p2gDnLqu5Ccg3lIbeou8D3lQUxQigKIpj83MfJOnSDjz+/d8889kDOvD07Af49jmF9KMZdq+Zyy3sW3sYGVj21Sr2rUnGarFlJZWXlXN4y3F+eXMBt796fdV7DEVlnC3KRBVkf/F++sB3HNlyvOrvkvxS/vvIj7y69Ok6L3JDcRlmo2NlnqXcQv7Zgqq/ty/ZY6cfW0lNawl+fJPKbK92vVoTFBZAaaF9PrvZaCYsxrdTVue8+wfLvlyDqcx5NXfHfu0a1yAfp6GOvTMwXJbl14Ay4ElFUbY23Kymj6HIsascgKXCUR5Yd7jKqVfn5L7TgO0m8NUTP3F4y3FMhnLC40K5+sErGDKlP1mpOZw976YBcPZYJgc3HKHH8C612hYZH05UYqRDOXpUQgQ9R3bj88d+5NS+0+ScyXP6fq3O9x/Z/TjStmcrAkIcHbvRYGLp5yu55nHfXC9Z/PkKfv9gmUNFtVqnJjw6hA5923H7P693/uaLlDp/obIs/wnEO3nphYr3RwKDgUsBRZblDoqiOHgsWZZnAjMBFEUhJsazj30ajcbjY9TGxBnj2f3nAQzF9j+itj1aExMTQ0iY8xlSUEggMTExfProt2yctx1htX2VhTlF/PLaAgZd0Y+wkDCEkwJTq1UQqA9y6bjvffcOPrjvS9KP2W4QkfHhTH5gPLP+/hu7Vuyv8X26QB3Drxt8wd+tt8/LxU5ki3Byzzimri75chVTHrvSZ9IGTWXl/PeRH9i3OtlBUKSSoJBAXl7yNGF+JS8H6nTsiqLUuFwuy/J9wJwKR75FlmUrEANknb+voiifA59X/Ck8XQzg7YKDVr1bMPiafmxbtJui3BK0ei2tuiZw80tTyM7OZtS0oexdd9BuISggJIBB1/QlOzubPav3Vzn1SnLO5DHrjd+47dXriGkdSXG+/SJSXNsYWvWOd+m4E7rH8Y+Fj7N69iZKCkoYecsQykpMKG/Pd9hXrVEREhlMUHgQ/a/sxeW3Dbrg77YRC5T8OMFaQ0GiscRE6sEztOnespEtckQIwZs3fsyx7Sm17mcuN/udeg009Jl6HjAaWCXLcmdAB/grVrBlJdz55o1cOXMUO5fvI6FTC3qP6laV9dJlUEfk5ybx57drKcotJjgsiKHXDuCy6y4FbPnlzigrNdo++62b+OKxHzl7PAthtRLXNpYb/z65XimVgaEBXDlzZNXfu/7c51SYQK1Vc/9/7iSpf3u7Pjl+mh49Lu/CiV2OC+dgSx30BQ6sO+yQpumM6FaRjWBN06Shjv1r4GtZlvcBJmCaszDMxUx8hziu+tto0g6l884tn5Gdmos+SEefMT24/pmrufymwZSVGNEH6cg6lcM3z/5MWVGZ05z4oLBARt8+DID2vVvz6tKnObj+CCZjOT0v79rgPPlO/dsT3SqSnDT72HpUYiQdL2nnd+rNgGsfv4q1szc5FOq1aB9Lhz7nZCRz0/PZOHcbYTGhDJrcr+raKikoBVFzzYY7OLLtuNNe6tXRBWp50J+3XiMNcuyKopgAf95bHRiKy/h45tekHzuXNJR+LAMhBPJzkwgMCWDzgp389PLcqqwUfZCO0JgQjCUmTAYTES3CGHrtpXTs27bqM9QaNT1HdHWbnSGRwQy7fiB/frOGkop+N2HRIVxx5/AmkePsCWRZfhJ4B4hVFKXJP42qNWoe++JePn30G1vLAQFx7WKQn5uEpmJRfMHHy/nzmzXkZxQiqST++PQvbntlKn98+lfVNRzfIY6Z799GRFwY2xbt5sSeVPqM6UGXQR3s4vRHt59g+TdrKMgswmQqJyBQR6f+7Zn0UM11I12HdEar/5Nyo2NGljZAS6+RXbnn3ZtrrIb2cxFWnnqDFT+st3PqYFO62f3XfuTnJmG1Wln48XK7VENjqQldoI5pb9xAoC6QDgPbEBodwqpZG0jefJT2fdoy6tahDrP0vLMFLP7vCorzShhx8xC6DKqfEvu1T06gz5ge/PntGtQaNeNnjKR114szZi3LcmtgLFB3XKAJcemVl/DPZU+zecFOhBAMmtSvqnYiNz2fP79ZW1XAJ6yC9KMZfDjjG4zVQjV56QV8MP1LVGoVp/anYTZZWPHDOroNSeLhL6ejUqv4/YOlLPx4OSaDfWrt/rWHObzlOO/89Q+n9nUZ1IEugzuxb3Wy3fbI+HBeWepfLHUFv2NvBGrqFVNWakIIQWF2MfmZhQ6vF+UUU5RTzDUvTOD0qdO8cf2HnNh9CovZyqZ5O1j/yxaenn1/VY+M3Sv2891zv5Bz2hZK2bF0D0OvvbRe3RcBOvZtS8e+t9fzKJsl7wFPA7972xB3ow/Sc/mNgx22b/p9O/kZBQ6RE/XTAAAIU0lEQVTbjaWO8ffUA6exVAuZlBUb2bPyAKt+2sDga/qz4KPlNSoZHd2RwpbFO+k4sI3Da5Ik8dg3M/jjs7/YvmQPJfml9L+yF/LzU/ziMC7id+yNwNBr+7Pp920Yiux/HDEtI5EkiaCwQAKC9RSeF/fUBmhJTLJlms7/cBlHq2UJCKvg5L40lDcWcPfbNyGEYO67i6ucOoChyMiWBTsZN30E8R18vijYp5BleTJwWlGU3bJce/96V1J5fSnNszZbEtsmoFKrHAVbnKycWZzEwS1mKwfXHUUjaWuWp8NWkLdvTTKDJvSrcZ/pr97K9FdvrfF1d+Ir58dddvgdeyOQdGkH+o7rxY6le6tyclu0j+WWf0wFbEo4PS/vwprTeXZapK27JdJrpC2Gfr6QdiVnKgqVSvJLyXMy0yrKLWHLwl1MfrjhvXCaG3XUaDwPuPSluZLK6+302+rUZkv3UUm0aB/rUDUdEKJ3yCfXBjh33iqtioNbD9dqg1avodvgTk3iO/ElO1xN5fU79kZAkiRmvn8bhzYfZ/2vW4hpFcUVdw23U226/Z/XExQWyL7VhzCXm0lMimdatYZhNYmABATZFGH0QXr0QY7qMBqdmoSO/tm6M2qq0ZBluRfQHqicrbcCdsiyPFBRlGbdT0EXoOX+T+7guxd+JTstF61WTftL2jJgQh9+fWshmRX99+PaxtB9eGc2zt1uF3sPiw1lwn2jSdmbxobfttU4TrverRk8eQC5ud4X/GiO+B17IyFJEl0Hd6TrYOeLmSqVihuenVSj2MfEB8dyZOsJu1h8aFQI42eMBGwzoO6XdSY7NdfuETmxcwL9r+ztvgO5CFAUZS9QdTeUZTkFGNAcsmJcoU2PVvzfvEcpKShFq9Ogq5CT6z2qG5vn2xZcB0/pR2BIAFEJEWyZv5PSQgNhsaFc+bdRtO3RipZJ8fz1zRpO7j997oMliGkdRf/xvbnuqQkXhfaot/A79iZCu16tueudm1j48XKKcooJjgxm7F2X24kk3PHaDeiD9exfexizqZz4DnHc+Ybs73zn54I4Xwc4MCSAkbcMsds25ZHxTHpoLOVGM7oAbVWqo0an4en/PcDsV+Zx5shZdIE6Lr9pcFUBnh/PctFpnjZF/MdSP/yap7XjK7b4ih3gO7a4S/PUP5Xz48ePn2aG37H78ePHTzPD79j9+PHjp5nhd+x+/Pjx08zwO3Y/fvz4aWb4HbsfP378NDO8lu7ojUH9XFR4Ld3RS+P6uXjw2XRHydP/ybK8vTHG8R+Lzx6Lt/D2cfvSOWgSdviSLS7aUSf+UIwfP378NDP8jt2PHz9+mhnN2bF/XvcuTQb/sTR9fOm4fcUWX7EDfMcWt9jhrcVTP378+PHjIZrzjN2PHz9+LkqaddteWZZfAmYAWRWbnlcUZZH3LKo/sixfCXwAqIEvFUV508smXTAVfc2LAAtgVhRlgHct8hyuXnuNcX5lWX4HmASYgGPAXYqi5DvZLwUPnJ+6jlGWZT3wPdAfyAFuVBQlxR1jnzdO64px4gEr8LmiKB+ct89IbBq3Jyo2zVEU5RUP2JJCLd+1LMsStu9sAlAK3Kkoyg5XP79ZO/YK3lMU5V1vG3EhyLKsBj4BxgJpwFZZlucrinLAu5Y1iFEXi2AFdVx7jXh+lwPPKYpilmX5LeA54Jka9nXr+XHxGKcDeYqidJJl+SbgLeBGd9lQDTPwhKIoO2RZDgW2y7K83Mn3vVZRlIkeGP98avuurwKSKv4bBHxW8X+X8IdifJuBwFFFUY4rimIC/gdM8bJNftxHo5xfRVGWKYpirvhzEzapv8bClWOcAnxX8e9fgTEVM1a3oihKeuWsV1GUIuAg0NLd47iJKcD3iqIIRVE2ARGyLCe4+uaLwbE/KMvyHlmWv5ZlOdLbxtSTlkB1Fes0fPdCdAUBLJNlebssyzO9bUwjUNe1543zezewuIbXPHF+XDnGqn0qbkAFQLSbxneKLMvtgL7AZicvD5Flebcsy4tlWe7hIRPq+q4bdG00+VBMHUrznwGvYvsSXwX+he3Cbio4m7U05TSmyxRFOSPLchywXJblZEVR1njbqAvFDdee285vbbYoivJ7xT4vYAtHzKrhYzxxflw5xka9zmVZDgF+Ax5VFKXwvJd3AG0VRSmWZXkCMA9bOMTd1PVdN+g7afKOvSal+fORZfkLYKGHzXE3aUDran+3AjyrKehBFEU5U/H/TFmW52J7TG+yjt0N157bzm9dtsiyPA2YCIxRFMWpg/DQ+XHlGCv3SZNlWQOEA7kNHNcpsixrsTn1WYqizDn/9eqOXlGURbIsfyrLcoy714Vc+K4bdG0061DMeTGpqcA+b9lygWwFkmRZbi/Lsg64CZjvZZsuCFmWgysWrJBlORgYR9M7Hy7j4rXXKOe3IivlGWCyoiilNezjqfPjyjHOB6ZV/Pt6YEVNN5+GUBG3/wo4qCjKv2vYJ74yvi/L8kBsPjLHzXa48l3PB+6QZVmSZXkwUKAoSrqrYzT5GXsdvC3L8iXYHmFSgL9515z6UZHF8CCwFFuq2NeKouz3slkXSgtgrizLYLvuflIUZYl3TfIoTq89WZYTsaX8TWjE8/sxoMf2yA+wSVGUe6vbgofOT03HKMvyK8A2RVHmY3O2P/x/+3Zog0AQRAH0V0Ij9DE5g8BBC1RCJdRBgr0+ziAQewIBghDM8J5cs5MVfzab2aqaM27q07f7vrFNsktyq6rrunZKsllrPWc0lmNV3ZMsSaYfNJmXZ11Vh6c6LhmjjnPGuOP+kw38PAVopvVTDMA/EuwAzQh2gGYEO0Azgh2gGcEO0IxgB2hGsAM08wBTwNas4JGdRwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_circle,y_circle = generate_dummy_circle_data(100)\n",
    "plt.subplot(121)\n",
    "plt.scatter(X_circle[:,0],X_circle[:,1],c=y_circle)\n",
    "\n",
    "X_spiral,y_spiral = generate_dummy_spiral_data(100,2)\n",
    "plt.subplot(122)\n",
    "plt.scatter(X_spiral[:,0],X_spiral[:,1],c=y_spiral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X \\in \\mathbb{R}^{N,D}$ - like the multinomial logistic regression, our data is also represented as a matrix with $N$ rows and $D$ columns, where each row is a $D$-dimensional feature vector representing an instance / example in our dataset $(x_i \\in \\mathbb{R}^D)$. In this particular example, $D=2$.\n",
    "\n",
    "$y \\in \\{0,..,C\\}^N$ - Given $C$ distinct classes, the prediction target is represented as a vector of length $N$ and each example $y_i$ is a scalar that can take on a value from 0 to $C$.\n",
    "\n",
    "**Note that the math expresses our target variable $y_i$ as a one-hot encoding vector, where it has a value of 1 corresponding to the correct class and 0 everywhere else. In practice, we represent $y_i$ as a scalar value denoting the index of the correct class instead. This is because it is not computationally and memory efficient to treat each $y_i$ as a vector, specially for large number of classes, when almost all of its values are 0.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X: (200, 2)\n",
      "The shape of y: (200,)\n",
      "\n",
      "First 5 examples:\n",
      "X[0] = [-0.42987855 -0.64571507]\t y[0] = 1\n",
      "X[1] = [ 0.75894653 -6.00768042]\t y[1] = 0\n",
      "X[2] = [-1.6867782   0.60434077]\t y[2] = 1\n",
      "X[3] = [3.42328594 3.64542926]\t y[3] = 0\n",
      "X[4] = [-0.1965121   0.43140486]\t y[4] = 1\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of X:\", X_circle.shape)\n",
    "print(\"The shape of y:\", y_circle.shape)\n",
    "print(\"\\nFirst 5 examples:\")\n",
    "for i in range(5):\n",
    "    print(\"X[{}] = {}\\t y[{}] = {}\".format(i, X_circle[i], i, y_circle[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Initialize Weights! We initialize the weights with small random values and the biases are initialized to zero.\n",
    "Open `neural_networks.py`, and fill in the code for the function `initialize_weights`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_networks import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "net = NeuralNetwork(hidden_size=6,num_classes=3)\n",
    "net.initialize_weights(input_dim=5)\n",
    "\n",
    "for param in net.params:\n",
    "    print(\"Shape of\",param, net.params[param].shape)\n",
    "\n",
    "for param in net.params:\n",
    "    print(param, net.params[param])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check:**\n",
    "    \n",
    "Expected Output\n",
    "```\n",
    "Shape of W1 (5, 6)\n",
    "Shape of b1 (6,)\n",
    "Shape of W2 (6, 3)\n",
    "Shape of b2 (3,)\n",
    "W1 [[ 0.01624345 -0.00611756 -0.00528172 -0.01072969  0.00865408 -0.02301539]\n",
    " [ 0.01744812 -0.00761207  0.00319039 -0.0024937   0.01462108 -0.02060141]\n",
    " [-0.00322417 -0.00384054  0.01133769 -0.01099891 -0.00172428 -0.00877858]\n",
    " [ 0.00042214  0.00582815 -0.01100619  0.01144724  0.00901591  0.00502494]\n",
    " [ 0.00900856 -0.00683728 -0.0012289  -0.00935769 -0.00267888  0.00530355]]\n",
    "b1 [ 0.  0.  0.  0.  0.  0.]\n",
    "W2 [[-0.00691661 -0.00396754 -0.00687173]\n",
    " [-0.00845206 -0.00671246 -0.00012665]\n",
    " [-0.0111731   0.00234416  0.01659802]\n",
    " [ 0.00742044 -0.00191836 -0.00887629]\n",
    " [-0.00747158  0.01692455  0.00050808]\n",
    " [-0.00636996  0.00190915  0.02100255]]\n",
    "b2 [ 0.  0.  0.]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Implement forward pass of a Fully Connected Layer (Also often called affine, linear, or dense layer)\n",
    "Open `neural_networks.py`, and fill in the code for the function `fully_connected_forward`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "net = NeuralNetwork(num_layers=2,num_classes=2, hidden_size=3)\n",
    "net.initialize_weights(input_dim=2)\n",
    "\n",
    "out, cache = net.fully_connected_forward(X_circle[:5],net.params['W1'], net.params['b1'])\n",
    "print(\"Fully Connected Layer Output:\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check:**\n",
    "    \n",
    "Expected Output\n",
    "```\n",
    "Fully Connected Layer Output:\n",
    "[[ -5.43922962e-05  -2.95825783e-03   1.71318792e-02]\n",
    " [  7.67884387e-02  -5.66338288e-02   1.34260549e-01]\n",
    " [ -3.38834903e-02   1.55489850e-02  -5.00005074e-03]\n",
    " [  1.64916743e-02   1.06056517e-02  -1.01981795e-01]\n",
    " [ -7.82087392e-03   4.93558593e-03  -8.89102840e-03]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Implement backward pass of a Fully Connected Layer.\n",
    "Open `neural_networks.py`, and fill in the code for the function `fully_connected_backward`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "net = NeuralNetwork()\n",
    "W1 = np.random.randn(2,5)\n",
    "b1 = np.random.randn(5)\n",
    "dUpper = np.random.randn(5, 5)\n",
    "\n",
    "out, cache = net.fully_connected_forward(X_circle[:5],W1, b1)\n",
    "\n",
    "dX, dW, db = net.fully_connected_backward(dUpper,cache)\n",
    "\n",
    "dX_num = compute_numerical_gradient(lambda X: np.sum(dUpper*net.fully_connected_forward(X, W1, b1)[0])\n",
    "                           , X_circle[:5])\n",
    "\n",
    "dW_num = compute_numerical_gradient(lambda W: np.sum(dUpper*net.fully_connected_forward(X_circle[:5], W, b1)[0])\n",
    "                           , W1)\n",
    "\n",
    "db_num = compute_numerical_gradient(lambda b: np.sum(dUpper*net.fully_connected_forward(X_circle[:5],W1, b)[0])\n",
    "                           ,  b1)\n",
    "\n",
    "print(\"Gradient dX Relative Error\",relative_error(dX, dX_num))\n",
    "print(\"Gradient dW Relative Error\",relative_error(dW, dW_num))\n",
    "print(\"Gradient db Relative Error\",relative_error(db, db_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check:**\n",
    "\n",
    "The relative errors of the gradients should be less than $10^{-8}$. The values may vary depending on your implementation.\n",
    "\n",
    "Largest Relative Errors in our implementation:\n",
    "```\n",
    "Gradient dX Relative Error 1.63516379584e-10\n",
    "Gradient dW Relative Error 5.41617890346e-09\n",
    "Gradient db Relative Error 5.70914573891e-11\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the forward pass of the Sigmoid activation function\n",
    "Open `neural_networks.py`, and fill in the code for the function `sigmoid_forward`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "net = NeuralNetwork()\n",
    "out, cache = net.sigmoid_forward(np.random.randn(5,5))\n",
    "print(\"Sigmoid Layer Output:\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check:**\n",
    "    \n",
    "Expected Output\n",
    "```\n",
    "Sigmoid Layer Output:\n",
    "[[ 0.83539354  0.35165864  0.3709434   0.25483894  0.70378922]\n",
    " [ 0.09099561  0.85129722  0.31838429  0.57909005  0.43797848]\n",
    " [ 0.81185487  0.11303172  0.42008677  0.40514941  0.75653387]\n",
    " [ 0.24976027  0.45699943  0.29362176  0.51055187  0.64171493]\n",
    " [ 0.2496239   0.75854586  0.71127629  0.62304533  0.71112537]]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Implement the backward pass of the Sigmoid activation function\n",
    "Open `neural_networks.py`, and fill in the code for the function `sigmoid_backward`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "net = NeuralNetwork()\n",
    "dUpper = np.random.randn(5, 5)\n",
    "dummy_input = np.random.randn(5,5)\n",
    "out, cache = net.sigmoid_forward(dummy_input)\n",
    "\n",
    "dSigmoid = net.sigmoid_backward(dUpper,cache)\n",
    "\n",
    "dSigmoid_num = compute_numerical_gradient(lambda X: np.sum(dUpper*net.sigmoid_forward(X)[0])\n",
    "                           , dummy_input)\n",
    "\n",
    "print(\"Gradient dSigmoid Relative Error\",relative_error(dSigmoid, dSigmoid_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check:**\n",
    "\n",
    "The relative errors of the gradients should be less than $10^{-8}$. The values may vary depending on your implementation.\n",
    "\n",
    "Largest Relative Error in our implementation:\n",
    "```\n",
    "Gradient dSigmoid Relative Error 2.8230695697e-10\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Implement softmax cross entropy loss layer\n",
    "Lets first implement softmax function that converts raw scores to probabilities.\n",
    "\n",
    "Open `neural_networks.py`, and fill in the code for the function `softmax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "net = NeuralNetwork()\n",
    "probs = net.softmax(np.array([[1001,1002,1003,1004,1005],[3,4,5,6,7]]))\n",
    "print(\"Probabilities of belonging to each class\")\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check:**\n",
    "    \n",
    "Expected Output:\n",
    "```\n",
    "Probabilities of belonging to each class\n",
    "[[ 0.01165623  0.03168492  0.08612854  0.23412166  0.63640865]\n",
    " [ 0.01165623  0.03168492  0.08612854  0.23412166  0.63640865]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, implement the softmax cross entropy loss and compute for its gradients. Since this is applied in the last layer, we do not need to worry about the gradients coming from after this layer.\n",
    "\n",
    "Open `neural_networks.py`, and fill in the code for the function `softmax_cross_entropy_loss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "net = NeuralNetwork()\n",
    "loss, dloss = net.softmax_cross_entropy_loss(np.random.randn(4,6),np.random.randint(0,6,size=4))\n",
    "print(\"Softmax Cross-entropy Loss\")\n",
    "print(loss)\n",
    "print()\n",
    "print(\"Gradient of the loss with respect to the scores\")\n",
    "print(dloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check:**\n",
    "    \n",
    "Expected Output:\n",
    "```\n",
    "Softmax Cross-entropy Loss\n",
    "3.23430146928\n",
    "\n",
    "Gradient of the loss with respect to the scores\n",
    "[[ 0.14058054  0.01502445  0.01633424  0.0094732   0.06581467 -0.24722709]\n",
    " [ 0.11190472  0.00913058  0.02689325 -0.23476698  0.0843474   0.00249103]\n",
    " [ 0.02967359 -0.22210018  0.12728696  0.01363695  0.03447541  0.01702727]\n",
    " [ 0.02501532  0.04295228 -0.24202226  0.07533903  0.0590784   0.03963723]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Build a simple network!\n",
    "Now that we have implemented two different types of layers, we can now build a simple neural network consisting of fully connected layers with relu activations.\n",
    "\n",
    "We will follow a simple feed forward neural network architecture as shown below:\n",
    "```\n",
    "Repeat for (Number of layers - 1): \n",
    "    [Fully Connected Layer] \n",
    "    [Activation Layer]\n",
    "\n",
    "[Fully Connected Layer] # (Output layer)\n",
    "```\n",
    "\n",
    "**Open `neural_networks.py`, and fill in the code for the function `network_forward`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "net = NeuralNetwork(num_layers=2, num_classes=3, hidden_size=10, hidden_activation_fn=\"sigmoid\")\n",
    "net.initialize_weights(5,std_dev=0.1)\n",
    "\n",
    "scores, cache_list  = net.network_forward(np.random.randn(5,5)*10)\n",
    "\n",
    "print(\"Forward Pass:\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check:**\n",
    "    \n",
    "Expected Output:\n",
    "```\n",
    "Forward Pass:\n",
    "[[ 0.19910154 -0.11077738  0.24974865]\n",
    " [ 0.26508479 -0.18731063  0.24634693]\n",
    " [ 0.3482853  -0.25223747 -0.06853373]\n",
    " [ 0.30067375 -0.14904403  0.18594437]\n",
    " [ 0.20967705 -0.07065423  0.10956096]]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute for the losses corresponding to the current parameters.\n",
    "Implement `loss` function which should output the losses as well as its the gradients. Note that the gradient computation of the layers is implemented in a separate function `network_backward` which you should also implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "net = NeuralNetwork(num_layers=2,num_classes=2, hidden_size=10, hidden_activation_fn=\"sigmoid\")\n",
    "net.initialize_weights(input_dim=2, std_dev=0.5)\n",
    "loss, grads = net.loss(X_circle[:5]*10, y_circle[:5], lambda_reg=0.0)\n",
    "for param in net.params:\n",
    "    f = lambda W: net.loss(X_circle[:5]*10, y_circle[:5], lambda_reg=0.0)[0]\n",
    "    param_grad_num = compute_numerical_gradient(f, net.params[param])\n",
    "    # Uncomment this if you want to print out the actual values for debugging.\n",
    "    # print(param + \"_numerical\", param_grad_num)\n",
    "    # print(param + \"_analytical\",grads[param])\n",
    "    print('{} Relative Error: {}'.format(param, relative_error(param_grad_num, grads[param])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relative errors of the gradients should be less than $10^{-8}$. The values may vary depending on your implementation.\n",
    "\n",
    "Largest Relative Errors in our implementation:\n",
    "```\n",
    "W1 Relative Error: 1.565689660633177e-08\n",
    "b1 Relative Error: 8.285555392599544e-09\n",
    "W2 Relative Error: 8.125385495575136e-11\n",
    "b2 Relative Error: 2.0095447739463423e-11\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "X = X_circle\n",
    "y = y_circle\n",
    "\n",
    "net = NeuralNetwork(num_layers=2, num_classes=2, hidden_size=6, hidden_activation_fn=\"sigmoid\")\n",
    "loss_history = net.train(X, y, learning_rate=0.9, lambda_reg=0.0, num_iters=1000, batch_size=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y_train_pred = net.predict(X)\n",
    "print(\"Train accuracy: {} %\".format(np.mean(Y_train_pred == y) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's visualize the training process!\n",
    "The code below will visualize the decision boundary (left) and the transformations (right) that the network learned during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "net = NeuralNetwork(num_layers=2, num_classes=2, hidden_size=6, hidden_activation_fn=\"sigmoid\")\n",
    "net.initialize_weights(X.shape[1],1)\n",
    "fig = plt.figure(figsize=(13,8))\n",
    "x_min, x_max = X[:,0].min() - 1, X[:,0].max() + 1\n",
    "y_min, y_max = X[:,1].min() - 1, X[:,1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.05),\n",
    "                     np.arange(y_min, y_max, 0.05))\n",
    "\n",
    "\n",
    "x1, y1 = np.meshgrid(np.arange(x_min, x_max, 1),\n",
    "                     np.arange(y_min, y_max, 1))\n",
    "\n",
    "grid_x = np.squeeze(np.stack((x1.ravel(),y1.ravel()))).T\n",
    "x_test = np.squeeze(np.stack((xx.ravel(),yy.ravel()))).T\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "for i in range(300):\n",
    "    \n",
    "    net.train_step(X, y, learning_rate=1, lambda_reg=0.0, batch_size=10)\n",
    "    if i % 10 == 0:\n",
    "\n",
    "        Z = net.predict(x_test)\n",
    "\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        ax1.clear()\n",
    "        ax1.contourf(xx, yy, Z)\n",
    "        ax1.scatter(X[:, 0], X[:, 1], c = y,cmap=\"jet\", edgecolors='black')\n",
    "        \n",
    "        Z, sc= net.predict(grid_x, return_scores=True)\n",
    "\n",
    "        ax2.clear()\n",
    "        for i in range(12):\n",
    "            ax2.plot(sc[i*x1.shape[0]:(i+1)*x1.shape[0],0],sc[i*x1.shape[0]: (i+1)*x1.shape[0],1], \"gray\", alpha=0.5)\n",
    "            ax2.plot(sc[np.arange(i,x1.shape[1]**2,x1.shape[1]),0],sc[np.arange(i,x1.shape[1]**2,x1.shape[1]),1], \"gray\", alpha=0.5)\n",
    "        ax2.scatter(sc[:,0],sc[:,1], c = Z, cmap=\"jet\")\n",
    "        \n",
    "        fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Let's try other activation functions and see how it affects the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the forward pass of the Tanh activation function\n",
    "Open `neural_networks.py`, and fill in the code for the function `tanh_forward`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "net = NeuralNetwork()\n",
    "out, cache = net.tanh_forward(np.random.randn(5,5))\n",
    "print(\"Tanh Layer Output:\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check:**\n",
    "    \n",
    "Expected Output\n",
    "```\n",
    "Tanh Layer Output:\n",
    "[[ 0.92525207 -0.5453623  -0.48398233 -0.79057703  0.69903334]\n",
    " [-0.98015695  0.94078216 -0.6417873   0.30863781 -0.24432671]\n",
    " [ 0.89806123 -0.96803916 -0.31169093 -0.36622326  0.81230541]\n",
    " [-0.80045996 -0.17073944 -0.70534482  0.04218869  0.52470857]\n",
    " [-0.80072132  0.8159986   0.71707154  0.46407656  0.71671439]]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Implement the backward pass of the Tanh activation function\n",
    "Open `neural_networks.py`, and fill in the code for the function `tanh_backward`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "net = NeuralNetwork()\n",
    "dUpper = np.random.randn(5, 5)\n",
    "dummy_input = np.random.randn(5,5)\n",
    "out, cache = net.tanh_forward(dummy_input)\n",
    "\n",
    "dTanh = net.tanh_backward(dUpper,cache)\n",
    "\n",
    "dTanh_num = compute_numerical_gradient(lambda X: np.sum(dUpper*net.tanh_forward(X)[0])\n",
    "                           , dummy_input)\n",
    "\n",
    "print(\"Gradient dTanh Relative Error\",relative_error(dTanh, dTanh_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check:**\n",
    "\n",
    "The relative errors of the gradients should be less than $10^{-8}$. The values may vary depending on your implementation.\n",
    "\n",
    "Largest Relative Error in our implementation:\n",
    "```\n",
    "Gradient dTanh Relative Error 1.48817404755e-09\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's visualize the decision boundaries and transformations under Tanh Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "net = NeuralNetwork(num_layers=2, num_classes=2, hidden_size=6, hidden_activation_fn=\"tanh\")\n",
    "net.initialize_weights(X.shape[1],1)\n",
    "fig = plt.figure(figsize=(13,8))\n",
    "x_min, x_max = X[:,0].min() - 1, X[:,0].max() + 1\n",
    "y_min, y_max = X[:,1].min() - 1, X[:,1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.05),\n",
    "                     np.arange(y_min, y_max, 0.05))\n",
    "\n",
    "\n",
    "x1, y1 = np.meshgrid(np.arange(x_min, x_max, 1),\n",
    "                     np.arange(y_min, y_max, 1))\n",
    "\n",
    "grid_x = np.squeeze(np.stack((x1.ravel(),y1.ravel()))).T\n",
    "x_test = np.squeeze(np.stack((xx.ravel(),yy.ravel()))).T\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "for i in range(300):\n",
    "    \n",
    "    net.train_step(X, y, learning_rate=1, lambda_reg=0.0, batch_size=10)\n",
    "    if i % 10 == 0:\n",
    "\n",
    "        Z = net.predict(x_test)\n",
    "\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        ax1.clear()\n",
    "        ax1.contourf(xx, yy, Z)\n",
    "        ax1.scatter(X[:, 0], X[:, 1], c = y,cmap=\"jet\", edgecolors='black')\n",
    "        \n",
    "        Z, sc= net.predict(grid_x, return_scores=True)\n",
    "\n",
    "        ax2.clear()\n",
    "        for i in range(12):\n",
    "            ax2.plot(sc[i*x1.shape[0]:(i+1)*x1.shape[0],0],sc[i*x1.shape[0]: (i+1)*x1.shape[0],1], \"gray\", alpha=0.5)\n",
    "            ax2.plot(sc[np.arange(i,x1.shape[1]**2,x1.shape[1]),0],sc[np.arange(i,x1.shape[1]**2,x1.shape[1]),1], \"gray\", alpha=0.5)\n",
    "        ax2.scatter(sc[:,0],sc[:,1], c = Z, cmap=\"jet\")\n",
    "        \n",
    "        fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Implement the forward pass of ReLU\n",
    "Open `neural_networks.py`, and fill in the code for the function `relu_forward`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "net = NeuralNetwork()\n",
    "out, cache = net.relu_forward(np.random.randn(5,5))\n",
    "print(\"ReLU Layer Output:\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check:**\n",
    "    \n",
    "Expected Output\n",
    "```\n",
    "ReLU Layer Output:\n",
    "[[ 1.62434536  0.          0.          0.          0.86540763]\n",
    " [ 0.          1.74481176  0.          0.3190391   0.        ]\n",
    " [ 1.46210794  0.          0.          0.          1.13376944]\n",
    " [ 0.          0.          0.          0.04221375  0.58281521]\n",
    " [ 0.          1.14472371  0.90159072  0.50249434  0.90085595]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Implement the backward pass of ReLU\n",
    "Open `neural_networks.py`, and fill in the code for the function `relu_backward`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "net = NeuralNetwork()\n",
    "dUpper = np.random.randn(5, 5)\n",
    "dummy_input = np.random.randn(5,5)\n",
    "out, cache = net.relu_forward(dummy_input)\n",
    "\n",
    "dRelu = net.relu_backward(dUpper,cache)\n",
    "\n",
    "dRelu_num = compute_numerical_gradient(lambda X: np.sum(dUpper*net.relu_forward(X)[0])\n",
    "                           , dummy_input)\n",
    "\n",
    "print(\"Gradient dRelu Relative Error\",relative_error(dRelu, dRelu_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check:**\n",
    "\n",
    "The relative errors of the gradients should be less than $10^{-8}$. The values may vary depending on your implementation.\n",
    "\n",
    "Largest Relative Error in our implementation:\n",
    "```\n",
    "Gradient dRelu Relative Error 5.71858102885e-11\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's visualize the decision boundaries and transformations under ReLU Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "net = NeuralNetwork(num_layers=2, num_classes=2, hidden_size=6, hidden_activation_fn=\"relu\")\n",
    "net.initialize_weights(X.shape[1],1)\n",
    "fig = plt.figure(figsize=(13,8))\n",
    "x_min, x_max = X[:,0].min() - 1, X[:,0].max() + 1\n",
    "y_min, y_max = X[:,1].min() - 1, X[:,1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.05),\n",
    "                     np.arange(y_min, y_max, 0.05))\n",
    "\n",
    "\n",
    "x1, y1 = np.meshgrid(np.arange(x_min, x_max, 1),\n",
    "                     np.arange(y_min, y_max, 1))\n",
    "\n",
    "grid_x = np.squeeze(np.stack((x1.ravel(),y1.ravel()))).T\n",
    "x_test = np.squeeze(np.stack((xx.ravel(),yy.ravel()))).T\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "for i in range(300):\n",
    "    \n",
    "    net.train_step(X, y, learning_rate=1, lambda_reg=0.0, batch_size=10)\n",
    "    if i % 10 == 0:\n",
    "\n",
    "        Z = net.predict(x_test)\n",
    "\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        ax1.clear()\n",
    "        ax1.contourf(xx, yy, Z)\n",
    "        ax1.scatter(X[:, 0], X[:, 1], c = y,cmap=\"jet\", edgecolors='black')\n",
    "        \n",
    "        Z, sc= net.predict(grid_x, return_scores=True)\n",
    "\n",
    "        ax2.clear()\n",
    "        for i in range(12):\n",
    "            ax2.plot(sc[i*x1.shape[0]:(i+1)*x1.shape[0],0],sc[i*x1.shape[0]: (i+1)*x1.shape[0],1], \"gray\", alpha=0.5)\n",
    "            ax2.plot(sc[np.arange(i,x1.shape[1]**2,x1.shape[1]),0],sc[np.arange(i,x1.shape[1]**2,x1.shape[1]),1], \"gray\", alpha=0.5)\n",
    "        ax2.scatter(sc[:,0],sc[:,1], c = Z, cmap=\"jet\")\n",
    "        \n",
    "        fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can compare the loss curves across the different activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "net = NeuralNetwork(num_layers=2, num_classes=2, hidden_size=6, hidden_activation_fn=\"sigmoid\")\n",
    "loss_history_sigmoid = net.train(X, y, learning_rate=0.8, lambda_reg=0.0, num_iters=1000, batch_size=10, verbose=False)\n",
    "\n",
    "net = NeuralNetwork(num_layers=2, num_classes=2, hidden_size=6, hidden_activation_fn=\"tanh\")\n",
    "loss_history_tanh = net.train(X, y, learning_rate=0.8, lambda_reg=0.0, num_iters=1000, batch_size=10, verbose=False)\n",
    "\n",
    "net = NeuralNetwork(num_layers=2, num_classes=2, hidden_size=6, hidden_activation_fn=\"relu\")\n",
    "loss_history_relu = net.train(X, y, learning_rate=0.8, lambda_reg=0.0, num_iters=1000, batch_size=10, verbose=False)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sig = plt.plot(loss_history_sigmoid, label='sigmoid')\n",
    "vl = plt.plot(loss_history_tanh, label='tanh')\n",
    "relu = plt.plot(loss_history_relu, label='ReLU')\n",
    "\n",
    "plt.title('Loss Curves')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(prop={'size': 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can also see how the size of the hidden layer affects the decision boundary. Let's start with sigmoid activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "plt_ctr = 1\n",
    "plt.figure(figsize=(15,10))\n",
    "for h_size in range(1,13, 2):\n",
    "    net = NeuralNetwork(num_layers=2, num_classes=2, hidden_size=h_size, hidden_activation_fn=\"sigmoid\")\n",
    "    loss_history_sigmoid = net.train(X, y, learning_rate=1, lambda_reg=0.0, num_iters=1000, batch_size=10, verbose=False)\n",
    "    \n",
    "    x_min, x_max = X[:,0].min() - 1, X[:,0].max() + 1\n",
    "    y_min, y_max = X[:,1].min() - 1, X[:,1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.05),\n",
    "                         np.arange(y_min, y_max, 0.05))\n",
    "\n",
    "    x_test = np.squeeze(np.stack((xx.ravel(),yy.ravel()))).T\n",
    "    \n",
    "    Z = net.predict(x_test).reshape(xx.shape)\n",
    "    plt.subplot(2,3,plt_ctr)\n",
    "    plt.contourf(xx, yy, Z)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c = y,cmap=\"jet\", edgecolors='black')\n",
    "    plt.title(\"hidden size = \"+str(h_size))\n",
    "    plt_ctr += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tanh activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "plt_ctr = 1\n",
    "plt.figure(figsize=(15,10))\n",
    "for h_size in range(1,13, 2):\n",
    "    net = NeuralNetwork(num_layers=2, num_classes=2, hidden_size=h_size, hidden_activation_fn=\"tanh\")\n",
    "    loss_history_sigmoid = net.train(X, y, learning_rate=1, lambda_reg=0.0, num_iters=1000, batch_size=10, verbose=False)\n",
    "    \n",
    "    x_min, x_max = X[:,0].min() - 1, X[:,0].max() + 1\n",
    "    y_min, y_max = X[:,1].min() - 1, X[:,1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.05),\n",
    "                         np.arange(y_min, y_max, 0.05))\n",
    "\n",
    "    x_test = np.squeeze(np.stack((xx.ravel(),yy.ravel()))).T\n",
    "    \n",
    "    Z = net.predict(x_test).reshape(xx.shape)\n",
    "    plt.subplot(2,3,plt_ctr)\n",
    "    plt.contourf(xx, yy, Z)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c = y,cmap=\"jet\", edgecolors='black')\n",
    "    plt.title(\"hidden size = \"+str(h_size))\n",
    "    plt_ctr += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "plt_ctr = 1\n",
    "plt.figure(figsize=(15,10))\n",
    "for h_size in range(1,13, 2):\n",
    "    net = NeuralNetwork(num_layers=2, num_classes=2, hidden_size=h_size, hidden_activation_fn=\"relu\")\n",
    "    loss_history_sigmoid = net.train(X, y, learning_rate=1, lambda_reg=0.0, num_iters=1000, batch_size=10, verbose=False)\n",
    "    \n",
    "    x_min, x_max = X[:,0].min() - 1, X[:,0].max() + 1\n",
    "    y_min, y_max = X[:,1].min() - 1, X[:,1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.05),\n",
    "                         np.arange(y_min, y_max, 0.05))\n",
    "\n",
    "    x_test = np.squeeze(np.stack((xx.ravel(),yy.ravel()))).T\n",
    "    \n",
    "    Z = net.predict(x_test).reshape(xx.shape)\n",
    "    plt.subplot(2,3,plt_ctr)\n",
    "    plt.contourf(xx, yy, Z)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c = y,cmap=\"jet\", edgecolors='black')\n",
    "    plt.title(\"hidden size = \"+str(h_size))\n",
    "    plt_ctr += 1\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
